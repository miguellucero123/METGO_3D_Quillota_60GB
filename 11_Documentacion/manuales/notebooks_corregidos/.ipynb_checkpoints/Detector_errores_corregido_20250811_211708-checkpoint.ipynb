{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475eeb6",
   "metadata": {
    "revision": {
     "advertencias": 6,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 1,
     "fecha": "2025-08-11T21:17:05.668038"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ================================================================================================\n",
    "# DETECTOR DE ERRORES ESPEC√çFICO PARA TU NOTEBOOK\n",
    "# \"Sistema de Pron√≥stico Meteorol√≥gico y Gesti√≥n Agr√≠cola MIP Quillota.ipynb\"\n",
    "# ================================================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import nbformat\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar rutas del proyecto\n",
    "PROJECT_PATH = r\"C:\\Users\\Alicia_Piero\\Documents\\Repo_AIEP\\MIP_QUILLOTA\\Proyecto_METGO_3D\"\n",
    "NOTEBOOK_NAME = \"Sistema de Pron√≥stico Meteorol√≥gico y Gesti√≥n Agr√≠cola MIP Quillota.ipynb\"\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "print(\"üöÄ DETECTOR DE ERRORES - NOTEBOOK MIP QUILLOTA\")\n",
    "print(\"=\"*65)\n",
    "print(f\"üìÇ Proyecto: {PROJECT_PATH}\")\n",
    "print(f\"üìì Notebook: {NOTEBOOK_NAME}\")\n",
    "\n",
    "# Verificar si existe el notebook\n",
    "notebook_path = os.path.join(PROJECT_PATH, NOTEBOOK_NAME)\n",
    "notebook_exists = os.path.exists(notebook_path)\n",
    "\n",
    "print(f\"\\nüìã VERIFICACI√ìN INICIAL:\")\n",
    "print(\"-\"*25)\n",
    "print(f\"‚úÖ Notebook encontrado: {notebook_exists}\")\n",
    "\n",
    "if notebook_exists:\n",
    "    size_mb = os.path.getsize(notebook_path) / (1024 * 1024)\n",
    "    print(f\"üìè Tama√±o del notebook: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå El notebook no se encuentra en la ruta especificada\")\n",
    "    print(\"üîç Buscando archivos .ipynb en el directorio...\")\n",
    "\n",
    "    import glob\n",
    "    notebooks = glob.glob(\"*.ipynb\")\n",
    "    if notebooks:\n",
    "        print(f\"üìì Notebooks encontrados:\")\n",
    "        for nb in notebooks:\n",
    "            print(f\"   - {nb}\")\n",
    "    else:\n",
    "        print(\"‚ùå No se encontraron notebooks en el directorio\")\n",
    "\n",
    "# Verificar entorno Jupyter\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "\n",
    "    if get_ipython():\n",
    "        print(f\"‚úÖ Ejecut√°ndose en Jupyter Lab\")\n",
    "        print(f\"üîß Directorio actual: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"‚ùå No detectado entorno Jupyter\")\n",
    "\n",
    "except ImportError:\n",
    "    print(f\"‚ùå Error importando IPython\")\n",
    "\n",
    "print(\"=\"*65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c4197",
   "metadata": {
    "revision": {
     "advertencias": 0,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 7,
     "fecha": "2025-08-11T21:17:06.364470"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ================================================================================================\n",
    "# ANALIZADOR ESPEC√çFICO DEL NOTEBOOK MIP QUILLOTA\n",
    "# ================================================================================================\n",
    "\n",
    "class MIPQuillotaNotebookAnalyzer:\n",
    "    def __init__(self, notebook_path):\n",
    "        self.notebook_path = notebook_path\n",
    "        self.notebook = None\n",
    "        self.errors_found = []\n",
    "        self.warnings = []\n",
    "        self.suggestions = []\n",
    "\n",
    "    def load_and_analyze_notebook(self):\n",
    "        \"\"\"Carga y analiza el notebook espec√≠fico\"\"\"\n",
    "        print(\"üìì AN√ÅLISIS DEL NOTEBOOK MIP QUILLOTA:\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        if not os.path.exists(self.notebook_path):\n",
    "            error_msg = f\"Notebook no encontrado: {self.notebook_path}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            self.errors_found.append(error_msg)\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            # Cargar notebook\n",
    "            with open(self.notebook_path, 'r', encoding='utf-8') as f:\n",
    "                self.notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "            print(f\"‚úÖ Notebook cargado exitosamente\")\n",
    "\n",
    "            # Realizar an√°lisis completo\n",
    "            self._analyze_notebook_structure()\n",
    "            self._analyze_imports_and_dependencies()\n",
    "            self._analyze_data_handling()\n",
    "            self._analyze_meteorological_code()\n",
    "            self._analyze_ml_models()\n",
    "            self._check_common_errors()\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error cargando notebook: {str(e)}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            self.errors_found.append(error_msg)\n",
    "            return False\n",
    "\n",
    "    def _analyze_notebook_structure(self):\n",
    "        \"\"\"Analiza la estructura general del notebook\"\"\"\n",
    "        print(f\"\\nüèóÔ∏è  ESTRUCTURA DEL NOTEBOOK:\")\n",
    "        print(\"-\"*30)\n",
    "\n",
    "        total_cells = len(self.notebook.cells)\n",
    "        code_cells = sum(\n",
    "            1 for cell in self.notebook.cells if cell.cell_type == 'code')\n",
    "        markdown_cells = sum(\n",
    "            1 for cell in self.notebook.cells if cell.cell_type == 'markdown')\n",
    "        empty_code_cells = sum(1 for cell in self.notebook.cells\n",
    "                               if cell.cell_type == 'code' and not cell.source.strip())\n",
    "\n",
    "        print(f\"   üìä Total celdas: {total_cells}\")\n",
    "        print(f\"   üêç Celdas c√≥digo: {code_cells}\")\n",
    "        print(f\"   üìù Celdas markdown: {markdown_cells}\")\n",
    "        print(f\"   ‚ö™ Celdas vac√≠as: {empty_code_cells}\")\n",
    "\n",
    "        if empty_code_cells > 5:\n",
    "            self.warnings.append(\n",
    "                f\"Muchas celdas de c√≥digo vac√≠as ({empty_code_cells})\")\n",
    "\n",
    "        # Verificar kernel\n",
    "        if 'kernelspec' in self.notebook.metadata:\n",
    "            kernel_info = self.notebook.metadata['kernelspec']\n",
    "            print(f\"   üîß Kernel: {kernel_info.get('display_name', 'N/A')}\")\n",
    "            print(f\"   üêç Lenguaje: {kernel_info.get('language', 'N/A')}\")\n",
    "        else:\n",
    "            self.warnings.append(\"Sin informaci√≥n de kernel definida\")\n",
    "\n",
    "        # Verificar outputs grandes\n",
    "        large_outputs = []\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type == 'code' and hasattr(cell, 'outputs'):\n",
    "                for output in cell.outputs:\n",
    "                    if hasattr(output, 'data') and output.data:\n",
    "                        # Estimar tama√±o del output\n",
    "                        output_str = str(output.data)\n",
    "                        if len(output_str) > 10000:  # > 10KB\n",
    "                            large_outputs.append(f\"Celda {i+1}\")\n",
    "\n",
    "        if large_outputs:\n",
    "            warning_msg = f\"Outputs grandes en: {', '.join(large_outputs)}\"\n",
    "            print(f\"   ‚ö†Ô∏è  {warning_msg}\")\n",
    "            self.warnings.append(warning_msg)\n",
    "\n",
    "    def _analyze_imports_and_dependencies(self):\n",
    "        \"\"\"Analiza imports y dependencias\"\"\"\n",
    "        print(f\"\\nüì¶ IMPORTS Y DEPENDENCIAS:\")\n",
    "        print(\"-\"*30)\n",
    "\n",
    "        all_imports = set()\n",
    "        missing_imports = []\n",
    "\n",
    "        # Extraer todos los imports\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type == 'code':\n",
    "                lines = cell.source.split('\\n')\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if line.startswith('import ') or line.startswith('from '):\n",
    "                        all_imports.add(line)\n",
    "\n",
    "        print(f\"   üìã Total imports √∫nicos: {len(all_imports)}\")\n",
    "\n",
    "        # Categorizar imports por tipo\n",
    "        standard_libs = []\n",
    "        data_science_libs = []\n",
    "        weather_libs = []\n",
    "        other_libs = []\n",
    "\n",
    "        for imp in all_imports:\n",
    "            if any(lib in imp.lower() for lib in [\n",
    "                   'pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']):\n",
    "                data_science_libs.append(imp)\n",
    "            elif any(lib in imp.lower() for lib in ['requests', 'json', 'datetime', 'os', 'sys']):\n",
    "                standard_libs.append(imp)\n",
    "            elif any(lib in imp.lower() for lib in ['meteostat', 'pyowm', 'weather', 'clima']):\n",
    "                weather_libs.append(imp)\n",
    "            else:\n",
    "                other_libs.append(imp)\n",
    "\n",
    "        print(f\"   üêç Librer√≠as est√°ndar: {len(standard_libs)}\")\n",
    "        print(f\"   üìä Librer√≠as data science: {len(data_science_libs)}\")\n",
    "        print(f\"   üå§Ô∏è  Librer√≠as meteorol√≥gicas: {len(weather_libs)}\")\n",
    "        print(f\"   üìö Otras librer√≠as: {len(other_libs)}\")\n",
    "\n",
    "        # Verificar librer√≠as cr√≠ticas para el proyecto\n",
    "        critical_libs = ['pandas', 'numpy', 'matplotlib', 'sklearn']\n",
    "        missing_critical = []\n",
    "\n",
    "        for lib in critical_libs:\n",
    "            if not any(lib in imp.lower() for imp in all_imports):\n",
    "                missing_critical.append(lib)\n",
    "\n",
    "        if missing_critical:\n",
    "            error_msg = f\"Librer√≠as cr√≠ticas faltantes: {missing_critical}\"\n",
    "            print(f\"   ‚ùå {error_msg}\")\n",
    "            self.errors_found.append(error_msg)\n",
    "\n",
    "        # Mostrar algunos imports importantes\n",
    "        if data_science_libs:\n",
    "            print(f\"\\n   üìä Principales imports data science:\")\n",
    "            for imp in sorted(data_science_libs)[:5]:\n",
    "                print(f\"      ‚Ä¢ {imp}\")\n",
    "\n",
    "        if weather_libs:\n",
    "            print(f\"\\n   üå§Ô∏è  Imports meteorol√≥gicos:\")\n",
    "            for imp in weather_libs:\n",
    "                print(f\"      ‚Ä¢ {imp}\")\n",
    "\n",
    "    def _analyze_data_handling(self):\n",
    "        \"\"\"Analiza el manejo de datos\"\"\"\n",
    "        print(f\"\\nüìä MANEJO DE DATOS:\")\n",
    "        print(\"-\"*20)\n",
    "\n",
    "        data_operations = {\n",
    "            'lectura_datos': ['pd.read_csv', 'pd.read_excel', 'pd.read_json', '.csv', '.xlsx'],\n",
    "            'limpieza_datos': ['.dropna()', '.fillna()', '.drop_duplicates()', '.isnull()'],\n",
    "            'transformacion': ['.groupby()', '.merge()', '.pivot()', '.melt()'],\n",
    "            'visualizacion': ['plt.', 'sns.', 'plotly', '.plot()', 'matplotlib']\n",
    "        }\n",
    "\n",
    "        operations_found = {key: [] for key in data_operations.keys()}\n",
    "\n",
    "        # Buscar operaciones en el c√≥digo\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type == 'code':\n",
    "                cell_source = cell.source.lower()\n",
    "\n",
    "                for operation_type, patterns in data_operations.items():\n",
    "                    for pattern in patterns:\n",
    "                        if pattern.lower() in cell_source:\n",
    "                            operations_found[operation_type].append(\n",
    "                                f\"Celda {i+1}\")\n",
    "                            break\n",
    "\n",
    "        # Reportar operaciones encontradas\n",
    "        for operation_type, cells in operations_found.items():\n",
    "            count = len(set(cells))  # Celdas √∫nicas\n",
    "            if count > 0:\n",
    "                print(\n",
    "                    f\"   ‚úÖ {\n",
    "                        operation_type.replace(\n",
    "                            '_',\n",
    "                            ' ').title()}: {count} celdas\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"   ‚ùå {\n",
    "                        operation_type.replace(\n",
    "                            '_',\n",
    "                            ' ').title()}: No encontrado\")\n",
    "\n",
    "                if operation_type == 'lectura_datos':\n",
    "                    self.warnings.append(\"No se detect√≥ carga de datos\")\n",
    "                elif operation_type == 'limpieza_datos':\n",
    "                    self.warnings.append(\"No se detect√≥ limpieza de datos\")\n",
    "\n",
    "    def _analyze_meteorological_code(self):\n",
    "        \"\"\"Analiza c√≥digo espec√≠fico meteorol√≥gico\"\"\"\n",
    "        print(f\"\\nüå§Ô∏è  AN√ÅLISIS METEOROL√ìGICO:\")\n",
    "        print(\"-\"*25)\n",
    "\n",
    "        meteo_keywords = {\n",
    "            'variables_meteo': ['temperatura', 'humedad', 'precipitacion', 'viento', 'presion'],\n",
    "            'unidades': ['celsius', '¬∞c', 'fahrenheit', 'mm', 'km/h', 'hpa', 'mb'],\n",
    "            'estaciones': ['primavera', 'verano', 'oto√±o', 'invierno'],\n",
    "            'agricola': ['cultivo', 'siembra', 'cosecha', 'riego', 'mip', 'quillota']\n",
    "        }\n",
    "\n",
    "        keywords_found = {key: [] for key in meteo_keywords.keys()}\n",
    "\n",
    "        # Buscar palabras clave meteorol√≥gicas\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type in ['code', 'markdown']:\n",
    "                cell_source = cell.source.lower()\n",
    "\n",
    "                for category, keywords in meteo_keywords.items():\n",
    "                    for keyword in keywords:\n",
    "                        if keyword in cell_source:\n",
    "                            keywords_found[category].append(keyword)\n",
    "\n",
    "        # Reportar hallazgos\n",
    "        for category, keywords in keywords_found.items():\n",
    "            unique_keywords = list(set(keywords))\n",
    "            if unique_keywords:\n",
    "                print(\n",
    "                    f\"   ‚úÖ {\n",
    "                        category.replace(\n",
    "                            '_',\n",
    "                            ' ').title()}: {\n",
    "                        len(unique_keywords)} t√©rminos\")\n",
    "                # Mostrar m√°ximo 5\n",
    "                print(f\"      {', '.join(unique_keywords[:5])}\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"   ‚ö†Ô∏è  {\n",
    "                        category.replace(\n",
    "                            '_',\n",
    "                            ' ').title()}: No encontrado\")\n",
    "\n",
    "        # Verificar rangos t√≠picos meteorol√≥gicos\n",
    "        range_checks = [\n",
    "            'temperatura.*(-?\\\\d+\\\\.?\\\\d*)',\n",
    "            'humedad.*(\\\\d+\\\\.?\\\\d*).*%',\n",
    "            'precipitacion.*(\\\\d+\\\\.?\\\\d*).*mm'\n",
    "        ]\n",
    "\n",
    "        print(f\"\\n   üîç Verificaci√≥n de rangos meteorol√≥gicos:\")\n",
    "        import re\n",
    "\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type == 'code':\n",
    "                for pattern in range_checks:\n",
    "                    matches = re.findall(pattern, cell.source, re.IGNORECASE)\n",
    "                    if matches:\n",
    "                        var_type = pattern.split('.*')[0]\n",
    "                        print(\n",
    "                            f\"      ‚Ä¢ {\n",
    "                                var_type.title()} detectada en celda {\n",
    "                                i+1}\")\n",
    "\n",
    "    def _analyze_ml_models(self):\n",
    "        \"\"\"Analiza modelos de machine learning\"\"\"\n",
    "        print(f\"\\nü§ñ MODELOS DE MACHINE LEARNING:\")\n",
    "        print(\"-\"*32)\n",
    "\n",
    "        ml_patterns = {\n",
    "            'sklearn_models': ['RandomForest', 'LinearRegression', 'SVM', 'KMeans', 'DecisionTree'],\n",
    "            'model_evaluation': ['train_test_split', 'cross_val_score', 'accuracy_score', 'mean_squared_error'],\n",
    "            'preprocessing': ['StandardScaler', 'MinMaxScaler', 'LabelEncoder', 'OneHotEncoder'],\n",
    "            'deep_learning': ['tensorflow', 'keras', 'pytorch', 'neural', 'deep']\n",
    "        }\n",
    "\n",
    "        ml_found = {key: [] for key in ml_patterns.keys()}\n",
    "\n",
    "        # Buscar patrones de ML\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type == 'code':\n",
    "                cell_source = cell.source\n",
    "\n",
    "                for category, patterns in ml_patterns.items():\n",
    "                    for pattern in patterns:\n",
    "                        if pattern in cell_source:\n",
    "                            ml_found[category].append(f\"Celda {i+1}\")\n",
    "                            break\n",
    "\n",
    "        # Reportar modelos encontrados\n",
    "        total_ml_indicators = sum(len(cells) for cells in ml_found.values())\n",
    "\n",
    "        if total_ml_indicators == 0:\n",
    "            print(f\"   ‚ö†Ô∏è  No se detectaron modelos de ML\")\n",
    "            self.warnings.append(\n",
    "                \"No se detectaron modelos de machine learning\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Indicadores de ML encontrados: {total_ml_indicators}\")\n",
    "\n",
    "            for category, cells in ml_found.items():\n",
    "                if cells:\n",
    "                    unique_cells = list(set(cells))\n",
    "                    print(\n",
    "                        f\"      ‚Ä¢ {\n",
    "                            category.replace(\n",
    "                                '_', ' ').title()}: {\n",
    "                            len(unique_cells)} celdas\")\n",
    "\n",
    "    def _check_common_errors(self):\n",
    "        \"\"\"Verifica errores comunes en notebooks\"\"\"\n",
    "        print(f\"\\nüîç VERIFICACI√ìN DE ERRORES COMUNES:\")\n",
    "        print(\"-\"*35)\n",
    "\n",
    "        common_issues = []\n",
    "\n",
    "        for i, cell in enumerate(self.notebook.cells):\n",
    "            if cell.cell_type == 'code':\n",
    "                source = cell.source\n",
    "\n",
    "                # Verificar errores comunes\n",
    "                if 'print(' in source and len(source.split('\\n')) == 1:\n",
    "                    common_issues.append(\n",
    "                        f\"Celda {\n",
    "                            i+1}: Print statement simple (posible debug)\")\n",
    "\n",
    "                if source.count('import') > 5:\n",
    "                    common_issues.append(\n",
    "                        f\"Celda {i+1}: Muchos imports en una celda\")\n",
    "\n",
    "                if len(source) > 2000:  # Celda muy larga\n",
    "                    common_issues.append(\n",
    "                        f\"Celda {\n",
    "                            i +\n",
    "                            1}: Celda muy larga ({\n",
    "                            len(source)} caracteres)\")\n",
    "\n",
    "                if '#TODO' in source or '#FIXME' in source:\n",
    "                    common_issues.append(\n",
    "                        f\"Celda {i+1}: Comentarios TODO/FIXME\")\n",
    "\n",
    "                # Verificar rutas hardcodeadas\n",
    "                if 'C:\\\\' in source or '/Users/' in source:\n",
    "                    common_issues.append(\n",
    "                        f\"Celda {i+1}: Ruta hardcodeada detectada\")\n",
    "\n",
    "        if common_issues:\n",
    "            print(f\"   ‚ö†Ô∏è  Problemas encontrados: {len(common_issues)}\")\n",
    "            for issue in common_issues[:10]:  # Mostrar m√°ximo 10\n",
    "                print(f\"      ‚Ä¢ {issue}\")\n",
    "            self.warnings.extend(common_issues)\n",
    "        else:\n",
    "            print(f\"   ‚úÖ No se encontraron problemas comunes\")\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Genera reporte final de an√°lisis\"\"\"\n",
    "        print(f\"\\nüìã REPORTE FINAL DEL AN√ÅLISIS:\")\n",
    "        print(\"=\"*35)\n",
    "\n",
    "        # Contar tipos de problemas\n",
    "        critical_errors = len(self.errors_found)\n",
    "        warnings_count = len(self.warnings)\n",
    "\n",
    "        print(f\"üìä Resumen:\")\n",
    "        print(f\"   ‚ùå Errores cr√≠ticos: {critical_errors}\")\n",
    "        print(f\"   ‚ö†Ô∏è  Advertencias: {warnings_count}\")\n",
    "\n",
    "        # Mostrar errores cr√≠ticos\n",
    "        if self.errors_found:\n",
    "            print(f\"\\n‚ùå ERRORES CR√çTICOS QUE REQUIEREN ATENCI√ìN:\")\n",
    "            for i, error in enumerate(self.errors_found, 1):\n",
    "                print(f\"   {i}. {error}\")\n",
    "\n",
    "        # Mostrar advertencias m√°s importantes\n",
    "        if self.warnings:\n",
    "            print(f\"\\n‚ö†Ô∏è  ADVERTENCIAS PRINCIPALES:\")\n",
    "            for i, warning in enumerate(self.warnings[:10], 1):  # Top 10\n",
    "                print(f\"   {i}. {warning}\")\n",
    "\n",
    "        # Sugerencias de mejora\n",
    "        print(f\"\\nüí° SUGERENCIAS DE MEJORA:\")\n",
    "        if not self.errors_found and not self.warnings:\n",
    "            print(\"   üéâ ¬°Excelente! No se encontraron problemas significativos\")\n",
    "        else:\n",
    "            print(\"   1. Revisar y corregir errores cr√≠ticos primero\")\n",
    "            print(\"   2. Agregar documentaci√≥n en celdas markdown\")\n",
    "            print(\"   3. Organizar imports en una sola celda al inicio\")\n",
    "            print(\"   4. Eliminar celdas de c√≥digo vac√≠as\")\n",
    "            print(\"   5. Validar rangos de datos meteorol√≥gicos\")\n",
    "            print(\"   6. Agregar manejo de errores (try-except)\")\n",
    "            print(\"   7. Usar rutas relativas en lugar de absolutas\")\n",
    "            print(\"   8. Limpiar outputs grandes innecesarios\")\n",
    "            print(\"   9. Agregar validaci√≥n de datos de entrada\")\n",
    "            print(\"   10. Documentar par√°metros de modelos ML\")\n",
    "\n",
    "        return {\n",
    "            'errors': self.errors_found,\n",
    "            'warnings': self.warnings,\n",
    "            'critical_count': critical_errors,\n",
    "            'warning_count': warnings_count\n",
    "        }\n",
    "\n",
    "\n",
    "# Crear analizador y ejecutar an√°lisis completo\n",
    "notebook_path = os.path.join(PROJECT_PATH, NOTEBOOK_NAME)\n",
    "analyzer = MIPQuillotaNotebookAnalyzer(notebook_path)\n",
    "\n",
    "print(\"üöÄ INICIANDO AN√ÅLISIS COMPLETO DEL NOTEBOOK...\")\n",
    "success = analyzer.load_and_analyze_notebook()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    report = analyzer.generate_report()\n",
    "    print(\"=\"*65)\n",
    "else:\n",
    "    print(\"‚ùå No se pudo completar el an√°lisis del notebook\")\n",
    "# Auto-fix: T√≠tulo agregado\n",
    "plt.title(\"An√°lisis Meteorol√≥gico - Quillota\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c69537",
   "metadata": {
    "revision": {
     "advertencias": 5,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 1,
     "fecha": "2025-08-11T21:17:06.844932"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ================================================================================================\n",
    "# PASO 1: DEFINIR LA CLASE DETECTIVE DE ERRORES\n",
    "# ================================================================================================\n",
    "\n",
    "import ast\n",
    "import re\n",
    "import sys\n",
    "import traceback\n",
    "from io import StringIO\n",
    "import os\n",
    "import nbformat\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class PythonErrorDetective:\n",
    "    def __init__(self, notebook_path):\n",
    "        self.notebook_path = notebook_path\n",
    "        self.notebook = None\n",
    "        self.errors_found = []\n",
    "        self.warnings_found = []\n",
    "        self.syntax_errors = []\n",
    "        self.problematic_cells = []\n",
    "\n",
    "    def load_and_analyze_notebook(self):\n",
    "        \"\"\"Carga el notebook y analiza cada celda\"\"\"\n",
    "        print(\"üïµÔ∏è DETECTIVE DE ERRORES EN ACCI√ìN:\")\n",
    "        print(\"=\" * 35)\n",
    "\n",
    "        try:\n",
    "            with open(self.notebook_path, 'r', encoding='utf-8') as f:\n",
    "                self.notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "            print(f\"üìì Notebook cargado: {len(self.notebook.cells)} celdas\")\n",
    "            print(f\"üîç Iniciando an√°lisis detallado...\")\n",
    "\n",
    "            # Analizar cada celda\n",
    "            for i, cell in enumerate(self.notebook.cells):\n",
    "                if cell.cell_type == 'code':\n",
    "                    self._analyze_cell_deep(i, cell)\n",
    "\n",
    "            # Mostrar resumen de problemas\n",
    "            self._show_error_summary()\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cargando notebook: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _analyze_cell_deep(self, cell_index, cell):\n",
    "        \"\"\"An√°lisis profundo de una celda espec√≠fica\"\"\"\n",
    "        cell_num = cell_index + 1\n",
    "        source_code = cell.source\n",
    "\n",
    "        if not source_code.strip():\n",
    "            return\n",
    "\n",
    "        print(f\"\\nüî¨ ANALIZANDO CELDA {cell_num}:\")\n",
    "        print(f\"   üìè Longitud: {len(source_code)} caracteres\")\n",
    "        print(f\"   üìÑ L√≠neas: {len(source_code.split(chr(10)))}\")\n",
    "\n",
    "        cell_problems = {\n",
    "            'cell_number': cell_num,\n",
    "            'syntax_errors': [],\n",
    "            'runtime_errors': [],\n",
    "            'warnings': [],\n",
    "            'code_smells': [],\n",
    "            'regex_issues': [],\n",
    "            'string_issues': [],\n",
    "            'source_length': len(source_code),\n",
    "            'line_count': len(source_code.split('\\n'))\n",
    "        }\n",
    "\n",
    "        # 1. AN√ÅLISIS DE SINTAXIS\n",
    "        syntax_ok = self._check_syntax_errors(source_code, cell_problems)\n",
    "\n",
    "        # 2. AN√ÅLISIS DE STRINGS (solo si hay problemas de sintaxis)\n",
    "        if not syntax_ok:\n",
    "            self._check_string_issues(source_code, cell_problems)\n",
    "\n",
    "        # 3. AN√ÅLISIS DE PATRONES PROBLEM√ÅTICOS\n",
    "        self._check_code_patterns(source_code, cell_problems)\n",
    "\n",
    "        # 4. AN√ÅLISIS DE IMPORTS\n",
    "        self._check_import_issues(source_code, cell_problems)\n",
    "\n",
    "        # Guardar problemas encontrados si los hay\n",
    "        if any(cell_problems[key] for key in ['syntax_errors', 'runtime_errors',\n",
    "               'warnings', 'code_smells', 'regex_issues', 'string_issues']):\n",
    "            self.problematic_cells.append(cell_problems)\n",
    "\n",
    "        # Mostrar problemas de esta celda\n",
    "        self._show_cell_problems(cell_problems)\n",
    "\n",
    "    def _check_syntax_errors(self, code, problems):\n",
    "        \"\"\"Detecta errores de sintaxis espec√≠ficos\"\"\"\n",
    "        try:\n",
    "            # Intentar compilar el c√≥digo\n",
    "            compile(code, f'<cell_{problems[\"cell_number\"]}>', 'exec')\n",
    "            print(\"   ‚úÖ Sintaxis v√°lida\")\n",
    "            return True\n",
    "\n",
    "        except SyntaxError as e:\n",
    "            error_info = {\n",
    "                'type': 'SyntaxError',\n",
    "                'message': str(e.msg) if e.msg else 'Error de sintaxis desconocido',\n",
    "                'line': e.lineno if e.lineno else 'N/A',\n",
    "                'column': e.offset if e.offset else 'N/A',\n",
    "                'text': e.text.strip() if e.text else 'N/A'\n",
    "            }\n",
    "\n",
    "            problems['syntax_errors'].append(error_info)\n",
    "            print(f\"   ‚ùå Error de sintaxis en l√≠nea {e.lineno}: {e.msg}\")\n",
    "\n",
    "            # An√°lisis espec√≠fico del error\n",
    "            if e.msg and 'unterminated string literal' in str(e.msg):\n",
    "                print(\"   üîç PROBLEMA DETECTADO: Cadena de texto no cerrada\")\n",
    "                self._analyze_string_termination_error(code, e, problems)\n",
    "\n",
    "            elif e.msg and 'invalid character' in str(e.msg):\n",
    "                print(\"   üîç PROBLEMA DETECTADO: Caracter inv√°lido\")\n",
    "                self._analyze_invalid_character_error(code, e, problems)\n",
    "\n",
    "            elif e.msg and 'unexpected EOF' in str(e.msg):\n",
    "                print(\"   üîç PROBLEMA DETECTADO: Final de archivo inesperado\")\n",
    "\n",
    "            return False\n",
    "\n",
    "        except Exception as e:\n",
    "            problems['runtime_errors'].append({\n",
    "                'type': type(e).__name__,\n",
    "                'message': str(e)\n",
    "            })\n",
    "            print(f\"   ‚ùå Error de compilaci√≥n: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _analyze_string_termination_error(self, code, syntax_error, problems):\n",
    "        \"\"\"Analiza errores de cadenas no terminadas\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        problem_line = syntax_error.lineno - 1 if syntax_error.lineno else 0\n",
    "\n",
    "        if 0 <= problem_line < len(lines):\n",
    "            line = lines[problem_line]\n",
    "\n",
    "            print(f\"      üìù L√≠nea problem√°tica: {line.strip()[:100]}...\")\n",
    "\n",
    "            # Contar comillas\n",
    "            single_quotes = line.count(\"'\")\n",
    "            double_quotes = line.count('\"')\n",
    "\n",
    "            print(f\"      üìä Comillas simples: {\n",
    "                  single_quotes}, dobles: {double_quotes}\")\n",
    "\n",
    "            # Detectar patrones espec√≠ficos\n",
    "            if r'\\\\' in line and ('r\"' in line or \"r'\" in line):\n",
    "                print(\n",
    "                    \"      üéØ CAUSA PROBABLE: Problema con raw string y barras invertidas\")\n",
    "                problems['string_issues'].append({\n",
    "                    'issue': 'raw_string_backslash',\n",
    "                    'line': problem_line + 1,\n",
    "                    'suggestion': 'Revisar escapado de barras invertidas en raw string',\n",
    "                    'line_content': line.strip()\n",
    "                })\n",
    "\n",
    "            elif single_quotes % 2 != 0:\n",
    "                print(\"      üéØ CAUSA PROBABLE: Comilla simple sin cerrar\")\n",
    "                problems['string_issues'].append({\n",
    "                    'issue': 'unclosed_single_quote',\n",
    "                    'line': problem_line + 1,\n",
    "                    'suggestion': 'Agregar comilla simple de cierre',\n",
    "                    'line_content': line.strip()\n",
    "                })\n",
    "\n",
    "            elif double_quotes % 2 != 0:\n",
    "                print(\"      üéØ CAUSA PROBABLE: Comilla doble sin cerrar\")\n",
    "                problems['string_issues'].append({\n",
    "                    'issue': 'unclosed_double_quote',\n",
    "                    'line': problem_line + 1,\n",
    "                    'suggestion': 'Agregar comilla doble de cierre',\n",
    "                    'line_content': line.strip()\n",
    "                })\n",
    "\n",
    "    def _analyze_invalid_character_error(self, code, syntax_error, problems):\n",
    "        \"\"\"Analiza errores de caracteres inv√°lidos\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        problem_line = syntax_error.lineno - 1 if syntax_error.lineno else 0\n",
    "\n",
    "        if 0 <= problem_line < len(lines):\n",
    "            line = lines[problem_line]\n",
    "            print(\n",
    "                f\"      üìù L√≠nea con caracter inv√°lido: {\n",
    "                    line.strip()[\n",
    "                        :100]}...\")\n",
    "\n",
    "            # Buscar caracteres no ASCII\n",
    "            non_ascii_chars = [char for char in line if ord(char) > 127]\n",
    "            if non_ascii_chars:\n",
    "                print(\n",
    "                    f\"      üîç Caracteres no-ASCII encontrados: {non_ascii_chars}\")\n",
    "                problems['string_issues'].append({\n",
    "                    'issue': 'non_ascii_character',\n",
    "                    'line': problem_line + 1,\n",
    "                    'suggestion': 'Eliminar o reemplazar caracteres no-ASCII',\n",
    "                    'characters': non_ascii_chars,\n",
    "                    'line_content': line.strip()\n",
    "                })\n",
    "\n",
    "    def _check_string_issues(self, code, problems):\n",
    "        \"\"\"Detecta problemas espec√≠ficos con strings\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            line_num = i + 1\n",
    "\n",
    "            # Detectar raw strings con problemas\n",
    "            if 'r\"' in line or \"r'\" in line:\n",
    "                if line.rstrip().endswith('\\\\'):\n",
    "                    problems['string_issues'].append({\n",
    "                        'issue': 'raw_string_trailing_backslash',\n",
    "                        'line': line_num,\n",
    "                        'content': line.strip(),\n",
    "                        'suggestion': 'Raw string no puede terminar con barra invertida'\n",
    "                    })\n",
    "                    print(\n",
    "                        f\"   ‚ö†Ô∏è  L√≠nea {line_num}: Raw string termina con \\\\\")\n",
    "\n",
    "            # Detectar l√≠neas muy largas con strings\n",
    "            if len(line) > 200 and ('\"' in line or \"'\" in line):\n",
    "                print(\n",
    "                    f\"   ‚ö†Ô∏è  L√≠nea {line_num}: L√≠nea muy larga con strings ({\n",
    "                        len(line)} chars)\")\n",
    "\n",
    "    def _check_code_patterns(self, code, problems):\n",
    "        \"\"\"Detecta patrones de c√≥digo problem√°ticos\"\"\"\n",
    "\n",
    "        # Buscar patrones problem√°ticos simples\n",
    "        if 'r\"' in code and code.count('\"') % 2 != 0:\n",
    "            problems['code_smells'].append({\n",
    "                'pattern': 'unmatched_quotes_with_raw_string',\n",
    "                'description': 'Raw string con comillas desbalanceadas',\n",
    "                'matches': 1\n",
    "            })\n",
    "            print(\"   üîç Patr√≥n problem√°tico: Raw string con comillas desbalanceadas\")\n",
    "\n",
    "        if '\\\\\\\\\\\\\\\\' in code:\n",
    "            problems['code_smells'].append({\n",
    "                'pattern': 'excessive_backslashes',\n",
    "                'description': 'Exceso de barras invertidas (posible sobre-escapado)',\n",
    "                'matches': code.count('\\\\\\\\\\\\\\\\')\n",
    "            })\n",
    "            print(\"   üîç Patr√≥n problem√°tico: Exceso de barras invertidas\")\n",
    "\n",
    "    def _check_import_issues(self, code, problems):\n",
    "        \"\"\"Detecta problemas con imports\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        import_count = 0\n",
    "\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(('import ', 'from ')):\n",
    "                import_count += 1\n",
    "\n",
    "        if import_count > 20:\n",
    "            problems['warnings'].append({\n",
    "                'type': 'too_many_imports',\n",
    "                'count': import_count,\n",
    "                'suggestion': 'Considerar organizar imports en celdas separadas'\n",
    "            })\n",
    "            print(f\"   ‚ö†Ô∏è  Muchos imports en esta celda: {import_count}\")\n",
    "\n",
    "    def _show_cell_problems(self, problems):\n",
    "        \"\"\"Muestra los problemas encontrados en una celda\"\"\"\n",
    "        total_problems = sum(len(problems[key]) for key in\n",
    "                             ['syntax_errors', 'string_issues', 'code_smells', 'warnings'])\n",
    "\n",
    "        if total_problems == 0:\n",
    "            print(\"   ‚úÖ No hay problemas detectados\")\n",
    "        else:\n",
    "            print(f\"   üìä Total de problemas en esta celda: {total_problems}\")\n",
    "\n",
    "    def _show_error_summary(self):\n",
    "        \"\"\"Muestra resumen completo de errores\"\"\"\n",
    "        print(f\"\\nüìã RESUMEN COMPLETO DE PROBLEMAS DETECTADOS:\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if not self.problematic_cells:\n",
    "            print(\"üéâ ¬°No se encontraron problemas en el notebook!\")\n",
    "            return\n",
    "\n",
    "        # Contar tipos de problemas\n",
    "        syntax_errors = sum(len(cell['syntax_errors'])\n",
    "                            for cell in self.problematic_cells)\n",
    "        string_issues = sum(len(cell['string_issues'])\n",
    "                            for cell in self.problematic_cells)\n",
    "        code_smells = sum(len(cell['code_smells'])\n",
    "                          for cell in self.problematic_cells)\n",
    "        warnings = sum(len(cell['warnings'])\n",
    "                       for cell in self.problematic_cells)\n",
    "\n",
    "        print(f\"üìä ESTAD√çSTICAS:\")\n",
    "        print(f\"   ‚Ä¢ Celdas con problemas: {len(self.problematic_cells)}\")\n",
    "        print(f\"   ‚Ä¢ Errores de sintaxis: {syntax_errors}\")\n",
    "        print(f\"   ‚Ä¢ Problemas con strings: {string_issues}\")\n",
    "        print(f\"   ‚Ä¢ Code smells: {code_smells}\")\n",
    "        print(f\"   ‚Ä¢ Advertencias: {warnings}\")\n",
    "\n",
    "        # Mostrar celdas m√°s problem√°ticas\n",
    "        print(f\"\\nüéØ CELDAS M√ÅS PROBLEM√ÅTICAS:\")\n",
    "        sorted_cells = sorted(self.problematic_cells,\n",
    "                              key=lambda x: len(\n",
    "                                  x['syntax_errors']) + len(x['string_issues']),\n",
    "                              reverse=True)\n",
    "\n",
    "        for i, cell_problems in enumerate(sorted_cells[:5], 1):  # Top 5\n",
    "            cell_num = cell_problems['cell_number']\n",
    "            syntax_count = len(cell_problems['syntax_errors'])\n",
    "            string_count = len(cell_problems['string_issues'])\n",
    "            total = syntax_count + string_count\n",
    "\n",
    "            if total > 0:\n",
    "                print(f\"   {i}. Celda {cell_num}: {total} problemas cr√≠ticos\")\n",
    "                if syntax_count > 0:\n",
    "                    print(f\"      ‚Ä¢ {syntax_count} errores de sintaxis\")\n",
    "                if string_count > 0:\n",
    "                    print(f\"      ‚Ä¢ {string_count} problemas con strings\")\n",
    "\n",
    "        return self.problematic_cells\n",
    "\n",
    "\n",
    "print(\"‚úÖ Clase PythonErrorDetective definida correctamente\")\n",
    "print(\"üöÄ Ahora puedes crear una instancia y analizar tu notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68861650",
   "metadata": {
    "revision": {
     "advertencias": 0,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 3,
     "fecha": "2025-08-11T21:17:06.890335"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ================================================================================================\n",
    "# PASO 2: EJECUTAR EL DETECTIVE EN TU NOTEBOOK\n",
    "# ================================================================================================\n",
    "\n",
    "# Ruta de tu notebook\n",
    "NOTEBOOK_PATH = r\"C:\\Users\\Alicia_Piero\\Documents\\Repo_AIEP\\MIP_QUILLOTA\\Proyecto_METGO_3D\\Sistema de Pron√≥stico Meteorol√≥gico y Gesti√≥n Agr√≠cola MIP Quillota.ipynb\"\n",
    "\n",
    "print(\"üïµÔ∏è DETECTIVE DE ERRORES - MIP QUILLOTA\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"üìÅ Analizando: {os.path.basename(NOTEBOOK_PATH)}\")\n",
    "\n",
    "# Crear detective\n",
    "detective_mip = PythonErrorDetective(NOTEBOOK_PATH)\n",
    "\n",
    "# Ejecutar an√°lisis\n",
    "success = detective_mip.load_and_analyze_notebook()\n",
    "\n",
    "print(f\"\\n‚è∞ An√°lisis completado: {datetime.now().strftime('%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824a324",
   "metadata": {
    "revision": {
     "advertencias": 0,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 2,
     "fecha": "2025-08-11T21:17:07.582782"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ================================================================================================\n",
    "# INSPECTOR DETALLADO DE ERRORES - AN√ÅLISIS PROFUNDO\n",
    "# ================================================================================================\n",
    "\n",
    "class DetailedErrorInspector:\n",
    "    def __init__(self, notebook_path):\n",
    "        self.notebook_path = notebook_path\n",
    "        self.notebook = None\n",
    "        self.detailed_errors = {}\n",
    "\n",
    "    def deep_inspect_specific_cells(self):\n",
    "        \"\"\"Inspecci√≥n profunda de las celdas problem√°ticas\"\"\"\n",
    "        print(\"üî¨ INSPECTOR DETALLADO DE ERRORES ESPEC√çFICOS:\")\n",
    "        print(\"=\" * 52)\n",
    "\n",
    "        with open(self.notebook_path, 'r', encoding='utf-8') as f:\n",
    "            self.notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "        # Inspeccionar celdas problem√°ticas identificadas\n",
    "        problematic_cells = [\n",
    "            (2, \"Exceso de imports\"),\n",
    "            (29, \"Error de sintaxis l√≠nea 477\"),\n",
    "            (30, \"String triple no cerrado\")\n",
    "        ]\n",
    "\n",
    "        for cell_num, description in problematic_cells:\n",
    "            print(\n",
    "                f\"\\nüéØ INSPECCI√ìN DETALLADA - CELDA {cell_num}: {description}\")\n",
    "            print(\"-\" * 60)\n",
    "            self._inspect_cell_deeply(cell_num - 1, description)\n",
    "\n",
    "        return self.detailed_errors\n",
    "\n",
    "    def _inspect_cell_deeply(self, cell_index, error_description):\n",
    "        \"\"\"Inspecci√≥n profunda de una celda espec√≠fica\"\"\"\n",
    "        cell = self.notebook.cells[cell_index]\n",
    "        cell_num = cell_index + 1\n",
    "        source = cell.source\n",
    "        lines = source.split('\\n')\n",
    "\n",
    "        self.detailed_errors[cell_num] = {\n",
    "            'description': error_description,\n",
    "            'source_length': len(source),\n",
    "            'line_count': len(lines),\n",
    "            'analysis': {},\n",
    "            'code_snippets': {},\n",
    "            'recommendations': []\n",
    "        }\n",
    "\n",
    "        print(f\"üìä Estad√≠sticas de la celda {cell_num}:\")\n",
    "        print(f\"   ‚Ä¢ Longitud total: {len(source):,} caracteres\")\n",
    "        print(f\"   ‚Ä¢ N√∫mero de l√≠neas: {len(lines):,}\")\n",
    "        print(f\"   ‚Ä¢ Promedio chars/l√≠nea: {len(source)/len(lines):.1f}\")\n",
    "\n",
    "        if cell_num == 2:\n",
    "            self._analyze_imports_excess(cell_num, source, lines)\n",
    "        elif cell_num == 29:\n",
    "            self._analyze_syntax_error_line_477(cell_num, source, lines)\n",
    "        elif cell_num == 30:\n",
    "            self._analyze_triple_quote_issue(cell_num, source, lines)\n",
    "\n",
    "    def _analyze_imports_excess(self, cell_num, source, lines):\n",
    "        \"\"\"An√°lisis detallado del exceso de imports en celda 2\"\"\"\n",
    "        print(f\"\\nüîç AN√ÅLISIS DETALLADO: Exceso de imports\")\n",
    "\n",
    "        imports = []\n",
    "        other_code = []\n",
    "        import_categories = {\n",
    "            'standard': [],\n",
    "            'data_science': [],\n",
    "            'visualization': [],\n",
    "            'ml': [],\n",
    "            'web_api': [],\n",
    "            'others': []\n",
    "        }\n",
    "\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            if line.strip().startswith(('import ', 'from ')):\n",
    "                imports.append({'line_num': i, 'code': line.strip()})\n",
    "\n",
    "                # Categorizar import\n",
    "                line_lower = line.lower()\n",
    "                if any(lib in line_lower for lib in [\n",
    "                       'os', 'sys', 'datetime', 'json', 're', 'math']):\n",
    "                    import_categories['standard'].append(line.strip())\n",
    "                elif any(lib in line_lower for lib in ['pandas', 'numpy', 'scipy']):\n",
    "                    import_categories['data_science'].append(line.strip())\n",
    "                elif any(lib in line_lower for lib in ['matplotlib', 'seaborn', 'plotly', 'bokeh']):\n",
    "                    import_categories['visualization'].append(line.strip())\n",
    "                elif any(lib in line_lower for lib in ['sklearn', 'tensorflow', 'keras', 'torch']):\n",
    "                    import_categories['ml'].append(line.strip())\n",
    "                elif any(lib in line_lower for lib in ['requests', 'urllib', 'api', 'http']):\n",
    "                    import_categories['web_api'].append(line.strip())\n",
    "                else:\n",
    "                    import_categories['others'].append(line.strip())\n",
    "            else:\n",
    "                if line.strip():\n",
    "                    other_code.append({'line_num': i, 'code': line.strip()})\n",
    "\n",
    "        print(f\"üìà Estad√≠sticas de imports:\")\n",
    "        print(f\"   ‚Ä¢ Total imports: {len(imports)}\")\n",
    "        print(f\"   ‚Ä¢ Librer√≠as est√°ndar: {len(import_categories['standard'])}\")\n",
    "        print(f\"   ‚Ä¢ Data Science: {len(import_categories['data_science'])}\")\n",
    "        print(f\"   ‚Ä¢ Visualizaci√≥n: {len(import_categories['visualization'])}\")\n",
    "        print(f\"   ‚Ä¢ Machine Learning: {len(import_categories['ml'])}\")\n",
    "        print(f\"   ‚Ä¢ Web/API: {len(import_categories['web_api'])}\")\n",
    "        print(f\"   ‚Ä¢ Otros: {len(import_categories['others'])}\")\n",
    "        print(f\"   ‚Ä¢ L√≠neas de c√≥digo adicional: {len(other_code)}\")\n",
    "\n",
    "        # Mostrar algunos ejemplos\n",
    "        print(f\"\\nüí° EJEMPLOS DE IMPORTS POR CATEGOR√çA:\")\n",
    "        for category, imports_list in import_categories.items():\n",
    "            if imports_list:\n",
    "                print(f\"   üîπ {category.title()}:\")\n",
    "                for imp in imports_list[:3]:  # Primeros 3\n",
    "                    print(f\"      ‚Ä¢ {imp}\")\n",
    "                if len(imports_list) > 3:\n",
    "                    print(f\"      ... y {len(imports_list) - 3} m√°s\")\n",
    "\n",
    "        # Guardar an√°lisis\n",
    "        self.detailed_errors[cell_num]['analysis'] = {\n",
    "            'total_imports': len(imports),\n",
    "            'categories': {k: len(v) for k, v in import_categories.items()},\n",
    "            'other_code_lines': len(other_code),\n",
    "            'import_details': import_categories\n",
    "        }\n",
    "\n",
    "        # Recomendaciones espec√≠ficas\n",
    "        recommendations = [\n",
    "            \"Separar imports en celda dedicada al inicio del notebook\",\n",
    "            \"Agrupar imports por categor√≠as (est√°ndar, data science, ML, etc.)\",\n",
    "            \"Mover c√≥digo funcional a celdas separadas\",\n",
    "            \"Considerar crear m√≥dulos .py para funciones reutilizables\"\n",
    "        ]\n",
    "\n",
    "        self.detailed_errors[cell_num]['recommendations'] = recommendations\n",
    "\n",
    "        print(f\"\\n‚ú® RECOMENDACIONES:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"   {i}. {rec}\")\n",
    "\n",
    "    def _analyze_syntax_error_line_477(self, cell_num, source, lines):\n",
    "        \"\"\"An√°lisis detallado del error de sintaxis en l√≠nea 477\"\"\"\n",
    "        print(f\"\\nüîç AN√ÅLISIS DETALLADO: Error de sintaxis l√≠nea 477\")\n",
    "\n",
    "        if len(lines) < 477:\n",
    "            print(f\"‚ùå ERROR: La celda solo tiene {len(lines)} l√≠neas, no 477\")\n",
    "            return\n",
    "\n",
    "        # Analizar l√≠nea problem√°tica y contexto\n",
    "        problem_line_idx = 476  # l√≠nea 477 (√≠ndice 476)\n",
    "        problem_line = lines[problem_line_idx]\n",
    "\n",
    "        # Contexto alrededor del error (5 l√≠neas antes y despu√©s)\n",
    "        context_start = max(0, problem_line_idx - 5)\n",
    "        context_end = min(len(lines), problem_line_idx + 6)\n",
    "        context_lines = lines[context_start:context_end]\n",
    "\n",
    "        print(f\"üìç L√çNEA PROBLEM√ÅTICA 477:\")\n",
    "        print(f\"   ‚îÇ {problem_line}\")\n",
    "        print(f\"   ‚îî‚îÄ Longitud: {len(problem_line)} caracteres\")\n",
    "\n",
    "        print(f\"\\nüìã CONTEXTO (l√≠neas {context_start + 1}-{context_end}):\")\n",
    "        for i, line in enumerate(context_lines, context_start + 1):\n",
    "            marker = \"üëâ\" if i == 477 else \"  \"\n",
    "            print(f\"   {marker} {i:3d}: {line[:80]}{\n",
    "                  '...' if len(line) > 80 else ''}\")\n",
    "\n",
    "        # An√°lisis espec√≠fico de la l√≠nea problem√°tica\n",
    "        analysis = {\n",
    "            'line_content': problem_line,\n",
    "            'line_length': len(problem_line),\n",
    "            'parentheses_balance': problem_line.count('(') - problem_line.count(')'),\n",
    "            'brackets_balance': problem_line.count('[') - problem_line.count(']'),\n",
    "            'braces_balance': problem_line.count('{') - problem_line.count('}'),\n",
    "            'single_quotes': problem_line.count(\"'\"),\n",
    "            'double_quotes': problem_line.count('\"'),\n",
    "            'has_colon': ':' in problem_line,\n",
    "            'ends_with_comma': problem_line.rstrip().endswith(','),\n",
    "            'potential_keywords': []\n",
    "        }\n",
    "\n",
    "        # Buscar keywords que podr√≠an necesitar ':'\n",
    "        keywords_needing_colon = [\n",
    "            'if',\n",
    "            'elif',\n",
    "            'else',\n",
    "            'for',\n",
    "            'while',\n",
    "            'def',\n",
    "            'class',\n",
    "            'try',\n",
    "            'except',\n",
    "            'finally',\n",
    "            'with']\n",
    "        for keyword in keywords_needing_colon:\n",
    "            if f' {keyword} ' in f' {problem_line} ' or problem_line.strip().startswith(f'{\n",
    "                    keyword} '):\n",
    "                analysis['potential_keywords'].append(keyword)\n",
    "\n",
    "        print(f\"\\nüîç AN√ÅLISIS DE LA L√çNEA 477:\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Balance par√©ntesis: {\n",
    "                analysis['parentheses_balance']} {\n",
    "                '‚ö†Ô∏è' if analysis['parentheses_balance'] != 0 else '‚úÖ'}\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Balance corchetes: {\n",
    "                analysis['brackets_balance']} {\n",
    "                '‚ö†Ô∏è' if analysis['brackets_balance'] != 0 else '‚úÖ'}\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Balance llaves: {\n",
    "                analysis['braces_balance']} {\n",
    "                '‚ö†Ô∏è' if analysis['braces_balance'] != 0 else '‚úÖ'}\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Comillas simples: {\n",
    "                analysis['single_quotes']} {\n",
    "                '‚ö†Ô∏è' if analysis['single_quotes'] %\n",
    "                2 != 0 else '‚úÖ'}\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Comillas dobles: {\n",
    "                analysis['double_quotes']} {\n",
    "                '‚ö†Ô∏è' if analysis['double_quotes'] %\n",
    "                2 != 0 else '‚úÖ'}\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Tiene dos puntos: {\n",
    "                '‚úÖ' if analysis['has_colon'] else '‚ùå'}\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Termina con coma: {\n",
    "                '‚úÖ' if analysis['ends_with_comma'] else '‚ùå'}\")\n",
    "\n",
    "        if analysis['potential_keywords']:\n",
    "            print(\n",
    "                f\"   ‚Ä¢ Keywords detectados: {\n",
    "                    ', '.join(\n",
    "                        analysis['potential_keywords'])}\")\n",
    "\n",
    "        # Guardar an√°lisis detallado\n",
    "        self.detailed_errors[cell_num]['analysis'] = analysis\n",
    "        self.detailed_errors[cell_num]['code_snippets'] = {\n",
    "            'problem_line': problem_line,\n",
    "            'context': context_lines,\n",
    "            'line_number': 477\n",
    "        }\n",
    "\n",
    "        # Generar recomendaciones espec√≠ficas\n",
    "        recommendations = []\n",
    "\n",
    "        if analysis['parentheses_balance'] > 0:\n",
    "            recommendations.append(\n",
    "                f\"Agregar {\n",
    "                    analysis['parentheses_balance']} par√©ntesis de cierre ')'\")\n",
    "        elif analysis['parentheses_balance'] < 0:\n",
    "            recommendations.append(\n",
    "                f\"Eliminar {abs(analysis['parentheses_balance'])} par√©ntesis de cierre extra\")\n",
    "\n",
    "        if analysis['brackets_balance'] > 0:\n",
    "            recommendations.append(\n",
    "                f\"Agregar {\n",
    "                    analysis['brackets_balance']} corchetes de cierre ']'\")\n",
    "        elif analysis['brackets_balance'] < 0:\n",
    "            recommendations.append(\n",
    "                f\"Eliminar {abs(analysis['brackets_balance'])} corchetes de cierre extra\")\n",
    "\n",
    "        if analysis['single_quotes'] % 2 != 0:\n",
    "            recommendations.append(\n",
    "                \"Balancear comillas simples (n√∫mero impar detectado)\")\n",
    "\n",
    "        if analysis['double_quotes'] % 2 != 0:\n",
    "            recommendations.append(\n",
    "                \"Balancear comillas dobles (n√∫mero impar detectado)\")\n",
    "\n",
    "        if analysis['potential_keywords'] and not analysis['has_colon']:\n",
    "            recommendations.append(\n",
    "                f\"Agregar ':' al final (keyword '{\n",
    "                    analysis['potential_keywords'][0]}' detectado)\")\n",
    "\n",
    "        if not recommendations:\n",
    "            recommendations.append(\n",
    "                \"Revisar sintaxis manualmente - error no identificado autom√°ticamente\")\n",
    "\n",
    "        self.detailed_errors[cell_num]['recommendations'] = recommendations\n",
    "\n",
    "        print(f\"\\n‚ú® RECOMENDACIONES ESPEC√çFICAS:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"   {i}. {rec}\")\n",
    "\n",
    "    def _analyze_triple_quote_issue(self, cell_num, source, lines):\n",
    "        \"\"\"An√°lisis detallado del problema de string triple\"\"\"\n",
    "        print(f\"\\nüîç AN√ÅLISIS DETALLADO: String triple no cerrado\")\n",
    "\n",
    "        # Analizar patrones de strings triples\n",
    "        triple_patterns = ['\"\"\"', \"'''\"]\n",
    "        analysis = {}\n",
    "\n",
    "        for pattern in triple_patterns:\n",
    "            count = source.count(pattern)\n",
    "            positions = []\n",
    "\n",
    "            # Encontrar todas las posiciones\n",
    "            start = 0\n",
    "            while True:\n",
    "                pos = source.find(pattern, start)\n",
    "                if pos == -1:\n",
    "                    break\n",
    "\n",
    "                # Determinar n√∫mero de l√≠nea\n",
    "                line_num = source[:pos].count('\\n') + 1\n",
    "                positions.append({'position': pos, 'line': line_num})\n",
    "                start = pos + len(pattern)\n",
    "\n",
    "            analysis[pattern] = {\n",
    "                'count': count,\n",
    "                'is_balanced': count % 2 == 0,\n",
    "                'positions': positions\n",
    "            }\n",
    "\n",
    "        print(f\"üìä AN√ÅLISIS DE STRINGS TRIPLES:\")\n",
    "        for pattern, info in analysis.items():\n",
    "            status = \"‚úÖ Balanceado\" if info['is_balanced'] else \"‚ùå Desbalanceado\"\n",
    "            print(f\"   ‚Ä¢ {pattern}: {info['count']} ocurrencias - {status}\")\n",
    "\n",
    "            if info['positions']:\n",
    "                print(f\"     Posiciones encontradas:\")\n",
    "                for pos_info in info['positions']:\n",
    "                    line_content = lines[pos_info['line'] -\n",
    "                                         1] if pos_info['line'] <= len(lines) else \"N/A\"\n",
    "                    print(\n",
    "                        f\"       - L√≠nea {pos_info['line']}: {line_content.strip()[:50]}...\")\n",
    "\n",
    "        # Identificar el problema espec√≠fico\n",
    "        problematic_pattern = None\n",
    "        for pattern, info in analysis.items():\n",
    "            if not info['is_balanced']:\n",
    "                problematic_pattern = pattern\n",
    "                break\n",
    "\n",
    "        if problematic_pattern:\n",
    "            problem_info = analysis[problematic_pattern]\n",
    "            print(f\"\\nüéØ PROBLEMA IDENTIFICADO:\")\n",
    "            print(f\"   ‚Ä¢ Patr√≥n problem√°tico: {problematic_pattern}\")\n",
    "            print(f\"   ‚Ä¢ √öltima posici√≥n: L√≠nea {\n",
    "                  problem_info['positions'][-1]['line']}\")\n",
    "\n",
    "            # Mostrar contexto de la √∫ltima ocurrencia\n",
    "            last_line = problem_info['positions'][-1]['line']\n",
    "            context_start = max(1, last_line - 3)\n",
    "            context_end = min(len(lines), last_line + 4)\n",
    "\n",
    "            print(f\"\\nüìã CONTEXTO (l√≠neas {context_start}-{context_end}):\")\n",
    "            for i in range(context_start, context_end + 1):\n",
    "                if i <= len(lines):\n",
    "                    marker = \"üëâ\" if i == last_line else \"  \"\n",
    "                    line_content = lines[i-1] if i > 0 else \"\"\n",
    "                    print(f\"   {marker} {i:3d}: {line_content}\")\n",
    "\n",
    "        # Guardar an√°lisis\n",
    "        self.detailed_errors[cell_num]['analysis'] = analysis\n",
    "        self.detailed_errors[cell_num]['code_snippets'] = {\n",
    "            'first_lines': lines[:10],\n",
    "            'last_lines': lines[-10:],\n",
    "            'total_lines': len(lines)\n",
    "        }\n",
    "\n",
    "        # Recomendaciones\n",
    "        recommendations = []\n",
    "        if problematic_pattern:\n",
    "            recommendations.append(\n",
    "                f\"Agregar {problematic_pattern} al final del c√≥digo para cerrar string\")\n",
    "            recommendations.append(\n",
    "                \"Revisar estructura del string para asegurar que el contenido sea correcto\")\n",
    "            recommendations.append(\n",
    "                \"Considerar dividir strings muy largos en secciones m√°s peque√±as\")\n",
    "        else:\n",
    "            recommendations.append(\n",
    "                \"Revisar manualmente la estructura de strings triples\")\n",
    "\n",
    "        self.detailed_errors[cell_num]['recommendations'] = recommendations\n",
    "\n",
    "        print(f\"\\n‚ú® RECOMENDACIONES:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"   {i}. {rec}\")\n",
    "\n",
    "    def generate_detailed_report(self):\n",
    "        \"\"\"Genera reporte detallado completo\"\"\"\n",
    "        print(f\"\\nüìã REPORTE DETALLADO COMPLETO:\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        for cell_num, details in self.detailed_errors.items():\n",
    "            print(f\"\\nüéØ CELDA {cell_num}: {details['description']}\")\n",
    "            print(\n",
    "                f\"   üìä Tama√±o: {\n",
    "                    details['source_length']:,    } chars, {\n",
    "                    details['line_count']:,        } l√≠neas\")\n",
    "            print(f\"   üîß Recomendaciones: {len(details['recommendations'])}\")\n",
    "\n",
    "        return self.detailed_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e0546",
   "metadata": {
    "revision": {
     "advertencias": 0,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 1,
     "fecha": "2025-08-11T21:17:07.608467"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ============================================================================\n",
    "# EJECUTAR INSPECTOR DETALLADO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ INICIANDO INSPECCI√ìN DETALLADA:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Crear inspector\n",
    "detailed_inspector = DetailedErrorInspector(NOTEBOOK_PATH)\n",
    "\n",
    "# Ejecutar inspecci√≥n profunda\n",
    "detailed_errors = detailed_inspector.deep_inspect_specific_cells()\n",
    "\n",
    "# Generar reporte completo\n",
    "full_report = detailed_inspector.generate_detailed_report()\n",
    "\n",
    "print(f\"\\n‚úÖ INSPECCI√ìN DETALLADA COMPLETADA\")\n",
    "print(\"üéØ SIGUIENTE PASO: Generar proyecto nuevo ordenado basado en este an√°lisis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c11cb1",
   "metadata": {
    "revision": {
     "advertencias": 17,
     "correcciones_aplicadas": 1,
     "errores_encontrados": 5,
     "fecha": "2025-08-11T21:17:08.441595"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECCIONES APLICADAS:\n",
    "# - Formato PEP8: Se aplic√≥ formato seg√∫n PEP8\n",
    "\n",
    "# ===============================================================================\n",
    "# üîß CONFIGURACI√ìN E IMPORTS - SISTEMA MIP QUILLOTA (REPARADO)\n",
    "# Manejo correcto del contexto de Streamlit\n",
    "# ===============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ===============================================================================\n",
    "# SUPRESI√ìN DE WARNINGS ESPEC√çFICOS - REPARADO\n",
    "# ===============================================================================\n",
    "\n",
    "# Filtrar solo los warnings molestos, mantener los importantes\n",
    "warnings.filterwarnings('ignore', message='.*ScriptRunContext.*')\n",
    "warnings.filterwarnings('ignore', message='.*missing ScriptRunContext.*')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='streamlit')\n",
    "\n",
    "# Configurar variables de entorno para Streamlit\n",
    "os.environ['STREAMLIT_BROWSER_GATHER_USAGE_STATS'] = 'false'\n",
    "os.environ['STREAMLIT_THEME_BASE'] = 'light'\n",
    "\n",
    "print(\"üöÄ Inicializando Sistema MIP Quillota...\")\n",
    "print(\"‚öôÔ∏è Configuraci√≥n de warnings optimizada\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===============================================================================\n",
    "# DETECCI√ìN DE CONTEXTO DE EJECUCI√ìN - MEJORADO\n",
    "# ===============================================================================\n",
    "\n",
    "\n",
    "def detect_execution_context():\n",
    "    \"\"\"Detecta si estamos ejecutando en notebook, streamlit o script\"\"\"\n",
    "    try:\n",
    "        # Verificar si estamos en Jupyter\n",
    "        if 'ipykernel' in sys.modules:\n",
    "            return 'jupyter'\n",
    "        # Verificar si estamos en Streamlit\n",
    "        elif 'streamlit' in sys.modules:\n",
    "            try:\n",
    "                import streamlit as st_test\n",
    "                # Verificar si el contexto de Streamlit est√° activo\n",
    "                try:\n",
    "                    st_test.session_state\n",
    "                    return 'streamlit_app'\n",
    "                except BaseException:\n",
    "                    return 'streamlit_script'\n",
    "            except BaseException:\n",
    "                return 'streamlit_import_only'\n",
    "        else:\n",
    "            return 'python_script'\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error detectando contexto: {e}\")\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "EXECUTION_CONTEXT = detect_execution_context()\n",
    "print(f\"üéØ Contexto de ejecuci√≥n detectado: {EXECUTION_CONTEXT}\")\n",
    "\n",
    "# ===============================================================================\n",
    "# IMPORTS B√ÅSICOS - SEGUROS\n",
    "# ===============================================================================\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime, timedelta, date\n",
    "    import json\n",
    "    import pickle\n",
    "\n",
    "    # Configurar pandas\n",
    "    pd.set_option('display.max_columns', 20)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.precision', 2)\n",
    "\n",
    "    print(\"‚úÖ Imports b√°sicos cargados correctamente\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error en imports b√°sicos: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===============================================================================\n",
    "# IMPORTS DE VISUALIZACI√ìN - SEGUROS\n",
    "# ===============================================================================\n",
    "\n",
    "try:\n",
    "    # Matplotlib y Seaborn\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Configuraci√≥n segura de matplotlib\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.figsize'] = (12, 8)\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "\n",
    "    print(\"‚úÖ Matplotlib y Seaborn cargados\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Error en matplotlib: {e}\")\n",
    "\n",
    "try:\n",
    "    # Plotly\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.figure_factory as ff\n",
    "\n",
    "    print(\"‚úÖ Plotly cargado\")\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Plotly no disponible: {e}\")\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "# ===============================================================================\n",
    "# IMPORTACI√ìN REPARADA DE STREAMLIT\n",
    "# ===============================================================================\n",
    "\n",
    "\n",
    "class StreamlitSafeManager:\n",
    "    \"\"\"Manager que maneja Streamlit de forma completamente segura\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.available = False\n",
    "        self.st = None\n",
    "        self.context = EXECUTION_CONTEXT\n",
    "        self._initialize_streamlit_safe()\n",
    "\n",
    "    def _initialize_streamlit_safe(self):\n",
    "        \"\"\"Inicializa Streamlit de la forma m√°s segura posible\"\"\"\n",
    "\n",
    "        # Redirigir stderr temporalmente para evitar warnings\n",
    "        original_stderr = sys.stderr\n",
    "\n",
    "        try:\n",
    "            # Crear un stderr silencioso\n",
    "            from io import StringIO\n",
    "            silent_stderr = StringIO()\n",
    "            sys.stderr = silent_stderr\n",
    "\n",
    "            # Intentar importar streamlit\n",
    "            import streamlit as st_module\n",
    "\n",
    "            # Restaurar stderr inmediatamente\n",
    "            sys.stderr = original_stderr\n",
    "\n",
    "            # Configurar seg√∫n contexto\n",
    "            if self.context == 'streamlit_app':\n",
    "                # Contexto completo de Streamlit\n",
    "                self.st = st_module\n",
    "                self.available = True\n",
    "                print(\"‚úÖ Streamlit completamente disponible\")\n",
    "\n",
    "            elif self.context in ['jupyter', 'python_script']:\n",
    "                # Crear wrapper compatible para notebooks\n",
    "                self.st = self._create_notebook_wrapper()\n",
    "                self.available = True\n",
    "                print(\"‚úÖ Streamlit en modo compatibilidad para notebook\")\n",
    "\n",
    "            else:\n",
    "                # Contexto desconocido, usar wrapper b√°sico\n",
    "                self.st = self._create_basic_wrapper()\n",
    "                self.available = False\n",
    "                print(\"‚ö†Ô∏è Streamlit en modo b√°sico\")\n",
    "\n",
    "        except ImportError:\n",
    "            # Restaurar stderr\n",
    "            sys.stderr = original_stderr\n",
    "\n",
    "            # Streamlit no disponible, crear mock\n",
    "            self.st = self._create_mock_streamlit()\n",
    "            self.available = False\n",
    "            print(\"‚ö†Ô∏è Streamlit no instalado - usando mock\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Restaurar stderr\n",
    "            sys.stderr = original_stderr\n",
    "\n",
    "            # Error inesperado, usar mock\n",
    "            self.st = self._create_mock_streamlit()\n",
    "            self.available = False\n",
    "            print(f\"‚ö†Ô∏è Error inicializando Streamlit: {e}\")\n",
    "\n",
    "    def _create_notebook_wrapper(self):\n",
    "        \"\"\"Crea wrapper optimizado para notebooks\"\"\"\n",
    "\n",
    "        class NotebookStreamlitWrapper:\n",
    "            \"\"\"Wrapper que adapta Streamlit para notebooks\"\"\"\n",
    "\n",
    "            def __init__(self):\n",
    "                self.session_state = {}\n",
    "                self._markdown_content = []\n",
    "\n",
    "            def write(self, *args, **kwargs):\n",
    "                if args:\n",
    "                    print(f\"üìù {args[0]}\")\n",
    "                return self\n",
    "\n",
    "            def markdown(self, text, **kwargs):\n",
    "                print(f\"üìÑ {text}\")\n",
    "                return self\n",
    "\n",
    "            def header(self, text, **kwargs):\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"üìã {text.upper()}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                return self\n",
    "\n",
    "            def subheader(self, text, **kwargs):\n",
    "                print(f\"\\n{'-'*40}\")\n",
    "                print(f\"üìå {text}\")\n",
    "                print(f\"{'-'*40}\")\n",
    "                return self\n",
    "\n",
    "            def metric(self, label, value, delta=None, **kwargs):\n",
    "                delta_text = f\" ({delta})\" if delta else \"\"\n",
    "                print(f\"üìä {label}: {value}{delta_text}\")\n",
    "                return self\n",
    "\n",
    "            def columns(self, num_cols):\n",
    "                return [self for _ in range(num_cols)]\n",
    "\n",
    "            def selectbox(self, label, options, **kwargs):\n",
    "                print(\n",
    "                    f\"üìã {label}: {\n",
    "                        options[0] if options else 'Sin opciones'}\")\n",
    "                return options[0] if options else None\n",
    "\n",
    "            def button(self, label, **kwargs):\n",
    "                print(f\"üîò Bot√≥n: {label}\")\n",
    "                return False\n",
    "\n",
    "            def sidebar(self):\n",
    "                return self\n",
    "\n",
    "            def plotly_chart(self, fig, **kwargs):\n",
    "                print(\"üìà Gr√°fico de Plotly mostrado\")\n",
    "                if PLOTLY_AVAILABLE:\n",
    "                    fig.show()\n",
    "                return self\n",
    "\n",
    "            def success(self, text):\n",
    "                print(f\"‚úÖ {text}\")\n",
    "                return self\n",
    "\n",
    "            def warning(self, text):\n",
    "                print(f\"‚ö†Ô∏è {text}\")\n",
    "                return self\n",
    "\n",
    "            def error(self, text):\n",
    "                print(f\"‚ùå {text}\")\n",
    "                return self\n",
    "\n",
    "            def info(self, text):\n",
    "                print(f\"‚ÑπÔ∏è {text}\")\n",
    "                return self\n",
    "\n",
    "            def set_page_config(self, **kwargs):\n",
    "                page_title = kwargs.get('page_title', 'App')\n",
    "                print(f\"üè† Configurando p√°gina: {page_title}\")\n",
    "                return self\n",
    "\n",
    "            def __getattr__(self, name):\n",
    "                # Para cualquier m√©todo no implementado\n",
    "                def generic_method(*args, **kwargs):\n",
    "                    if args:\n",
    "                        print(f\"üîß [{name.upper()}]: {args[0]}\")\n",
    "                    return self\n",
    "                return generic_method\n",
    "\n",
    "        return NotebookStreamlitWrapper()\n",
    "\n",
    "    def _create_basic_wrapper(self):\n",
    "        \"\"\"Wrapper b√°sico silencioso\"\"\"\n",
    "        class BasicWrapper:\n",
    "            def __init__(self):\n",
    "                self.session_state = {}\n",
    "\n",
    "            def __getattr__(self, name):\n",
    "                def dummy(*args, **kwargs):\n",
    "                    return self\n",
    "                return dummy\n",
    "\n",
    "        return BasicWrapper()\n",
    "\n",
    "    def _create_mock_streamlit(self):\n",
    "        \"\"\"Mock completo de Streamlit\"\"\"\n",
    "        class MockStreamlit:\n",
    "            def __init__(self):\n",
    "                self.session_state = {}\n",
    "\n",
    "            def __getattr__(self, name):\n",
    "                def mock_function(*args, **kwargs):\n",
    "                    return self\n",
    "                return mock_function\n",
    "\n",
    "        return MockStreamlit()\n",
    "\n",
    "\n",
    "# Inicializar manager de Streamlit\n",
    "streamlit_manager = StreamlitSafeManager()\n",
    "st = streamlit_manager.st\n",
    "\n",
    "print(f\"‚úÖ Streamlit manager inicializado (disponible: {\n",
    "      streamlit_manager.available})\")\n",
    "\n",
    "# ===============================================================================\n",
    "# IMPORTS DE MACHINE LEARNING - OPCIONALES\n",
    "# ===============================================================================\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    from scipy import stats\n",
    "    ML_AVAILABLE = True\n",
    "    print(\"‚úÖ Librer√≠as de ML cargadas\")\n",
    "except ImportError as e:\n",
    "    ML_AVAILABLE = False\n",
    "    print(f\"‚ö†Ô∏è Algunas librer√≠as de ML no disponibles: {e}\")\n",
    "\n",
    "# ===============================================================================\n",
    "# CONFIGURACI√ìN DEL PROYECTO - PATHS SEGUROS\n",
    "# ===============================================================================\n",
    "\n",
    "# Detectar directorio actual de forma segura\n",
    "try:\n",
    "    current_path = Path.cwd()\n",
    "    PROJECT_ROOT = current_path.parent if 'notebooks' in current_path.parts else current_path\n",
    "\n",
    "    # Directorios del proyecto\n",
    "    NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "    SRC_DIR = PROJECT_ROOT / 'src'\n",
    "    DATA_DIR = PROJECT_ROOT / 'data'\n",
    "    DOCS_DIR = PROJECT_ROOT / 'docs'\n",
    "    TESTS_DIR = PROJECT_ROOT / 'tests'\n",
    "\n",
    "    # Crear directorios si no existen (solo si tenemos permisos)\n",
    "    for directory in [SRC_DIR, DATA_DIR, DOCS_DIR, TESTS_DIR]:\n",
    "        try:\n",
    "            directory.mkdir(exist_ok=True)\n",
    "            # Crear __init__.py solo si es necesario\n",
    "            init_file = directory / '__init__.py'\n",
    "            if not init_file.exists() and directory.name == 'src':\n",
    "                init_file.touch()\n",
    "        except PermissionError:\n",
    "            print(f\"‚ö†Ô∏è Sin permisos para crear {directory}\")\n",
    "\n",
    "    # A√±adir al path de forma segura\n",
    "    for path in [PROJECT_ROOT, SRC_DIR]:\n",
    "        path_str = str(path)\n",
    "        if path_str not in sys.path and path.exists():\n",
    "            sys.path.insert(0, path_str)\n",
    "\n",
    "    print(f\"üìÅ Directorio del proyecto: {PROJECT_ROOT}\")\n",
    "    print(f\"üìÅ Notebooks: {'‚úÖ' if NOTEBOOKS_DIR.exists() else '‚ùå'}\")\n",
    "    print(f\"üìÅ C√≥digo fuente: {'‚úÖ' if SRC_DIR.exists() else '‚ùå'}\")\n",
    "    print(f\"üìÅ Datos: {'‚úÖ' if DATA_DIR.exists() else '‚ùå'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error configurando directorios: {e}\")\n",
    "    # Configuraci√≥n m√≠nima de respaldo\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "    DATA_DIR = PROJECT_ROOT / 'data'\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ===============================================================================\n",
    "# CONFIGURACI√ìN ESPEC√çFICA DE QUILLOTA\n",
    "# ===============================================================================\n",
    "\n",
    "QUILLOTA_CONFIG = {\n",
    "    'ubicacion': {\n",
    "        'nombre': 'Quillota',\n",
    "        'region': 'Valpara√≠so',\n",
    "        'pais': 'Chile',\n",
    "        'latitud': -32.8833,\n",
    "        'longitud': -71.25,\n",
    "        'elevacion': 120,\n",
    "        'zona_horaria': 'America/Santiago'\n",
    "    },\n",
    "\n",
    "    'clima': {\n",
    "        'tipo': 'Mediterr√°neo c√°lido',\n",
    "        'temperatura_media_anual': 16.5,\n",
    "        'precipitacion_anual_promedio': 400,\n",
    "        'meses_secos': [11, 12, 1, 2, 3],\n",
    "        'meses_lluviosos': [5, 6, 7, 8]\n",
    "    },\n",
    "\n",
    "    'agricultura': {\n",
    "        'cultivos_principales': ['paltas', 'citricos', 'uvas', 'hortalizas'],\n",
    "        'temporada_crecimiento': {'inicio': 9, 'fin': 4},\n",
    "        'riego': {\n",
    "            'sistema_principal': 'goteo',\n",
    "            'fuente_agua': ['Rio Aconcagua', 'Pozos']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'riesgos_climaticos': {\n",
    "        'heladas': 'Mayo a Septiembre',\n",
    "        'sequias': 'Diciembre a Marzo',\n",
    "        'vientos_fuertes': 'Agosto a Octubre'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Umbrales cr√≠ticos\n",
    "UMBRALES_CRITICOS = {\n",
    "    'temperatura': {\n",
    "        'helada_severa': -2,\n",
    "        'helada_moderada': 0,\n",
    "        'calor_extremo': 35,\n",
    "        'calor_alto': 30\n",
    "    },\n",
    "    'precipitacion': {\n",
    "        'sequia_dias': 30,\n",
    "        'lluvia_intensa': 20,\n",
    "        'lluvia_extrema': 50\n",
    "    },\n",
    "    'viento': {\n",
    "        'moderado': 15,\n",
    "        'fuerte': 25,\n",
    "        'muy_fuerte': 40\n",
    "    },\n",
    "    'humedad': {\n",
    "        'muy_baja': 30,\n",
    "        'muy_alta': 85\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n de Quillota cargada\")\n",
    "\n",
    "# ===============================================================================\n",
    "# FUNCIONES UTILITARIAS REPARADAS\n",
    "# ===============================================================================\n",
    "\n",
    "\n",
    "def crear_datos_meteorologicos(dias=365):\n",
    "    \"\"\"Genera datos meteorol√≥gicos simulados para Quillota\"\"\"\n",
    "    try:\n",
    "        np.random.seed(42)\n",
    "        fechas = pd.date_range(start='2024-01-01', periods=dias, freq='D')\n",
    "\n",
    "        datos = pd.DataFrame({\n",
    "            'fecha': fechas,\n",
    "            'temperatura_max': np.random.normal(22, 6, dias),\n",
    "            'temperatura_min': np.random.normal(10, 4, dias),\n",
    "            'humedad_relativa': np.clip(np.random.normal(65, 15, dias), 20, 95),\n",
    "            'precipitacion': np.random.exponential(0.8, dias),\n",
    "            'velocidad_viento': np.clip(np.random.normal(8, 3, dias), 0, 40),\n",
    "            'direccion_viento': np.random.choice(['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'], dias),\n",
    "            'presion_atmosferica': np.random.normal(1013, 8, dias),\n",
    "            'radiacion_solar': np.clip(np.random.normal(18, 6, dias), 0, 30)\n",
    "        })\n",
    "\n",
    "        # Ajustes estacionales para Chile\n",
    "        for i, fecha in enumerate(datos['fecha']):\n",
    "            mes = fecha.month\n",
    "            if mes in [12, 1, 2]:  # Verano\n",
    "                datos.loc[i, 'temperatura_max'] += 8\n",
    "                datos.loc[i, 'temperatura_min'] += 5\n",
    "                datos.loc[i, 'precipitacion'] *= 0.2\n",
    "            elif mes in [6, 7, 8]:  # Invierno\n",
    "                datos.loc[i, 'temperatura_max'] -= 6\n",
    "                datos.loc[i, 'temperatura_min'] -= 4\n",
    "                datos.loc[i, 'precipitacion'] *= 2.5\n",
    "\n",
    "        return datos\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generando datos: {e}\")\n",
    "        # Retornar datos m√≠nimos en caso de error\n",
    "        return pd.DataFrame({\n",
    "            'fecha': pd.date_range('2024-01-01', periods=7),\n",
    "            'temperatura_max': [20] * 7,\n",
    "            'temperatura_min': [10] * 7,\n",
    "            'humedad_relativa': [60] * 7,\n",
    "            'precipitacion': [0] * 7,\n",
    "            'velocidad_viento': [8] * 7,\n",
    "            'direccion_viento': ['W'] * 7,\n",
    "            'presion_atmosferica': [1013] * 7,\n",
    "            'radiacion_solar': [18] * 7\n",
    "        })\n",
    "\n",
    "\n",
    "def evaluar_alertas(datos_dia):\n",
    "    \"\"\"Eval√∫a alertas meteorol√≥gicas de forma segura\"\"\"\n",
    "    try:\n",
    "        alertas = []\n",
    "\n",
    "        if datos_dia['temperatura_min'] <= UMBRALES_CRITICOS['temperatura']['helada_severa']:\n",
    "            alertas.append(\n",
    "                'üßä HELADA SEVERA - Proteger cultivos inmediatamente')\n",
    "        elif datos_dia['temperatura_min'] <= UMBRALES_CRITICOS['temperatura']['helada_moderada']:\n",
    "            alertas.append(\n",
    "                '‚ùÑÔ∏è RIESGO DE HELADA - Monitorear cultivos sensibles')\n",
    "\n",
    "        if datos_dia['temperatura_max'] >= UMBRALES_CRITICOS['temperatura']['calor_extremo']:\n",
    "            alertas.append('üî• CALOR EXTREMO - Aumentar frecuencia de riego')\n",
    "\n",
    "        if datos_dia['velocidad_viento'] >= UMBRALES_CRITICOS['viento']['fuerte']:\n",
    "            alertas.append(\n",
    "                'üí® VIENTO FUERTE - Revisar estructuras y sistemas de soporte')\n",
    "\n",
    "        if datos_dia['precipitacion'] >= UMBRALES_CRITICOS['precipitacion']['lluvia_intensa']:\n",
    "            alertas.append('üåßÔ∏è LLUVIA INTENSA - Revisar sistemas de drenaje')\n",
    "\n",
    "        if datos_dia['humedad_relativa'] <= UMBRALES_CRITICOS['humedad']['muy_baja']:\n",
    "            alertas.append('üèúÔ∏è HUMEDAD MUY BAJA - Considerar riego adicional')\n",
    "        elif datos_dia['humedad_relativa'] >= UMBRALES_CRITICOS['humedad']['muy_alta']:\n",
    "            alertas.append(\n",
    "                'üíß HUMEDAD MUY ALTA - Riesgo de enfermedades f√∫ngicas')\n",
    "\n",
    "        return alertas if alertas else ['‚úÖ Condiciones clim√°ticas favorables']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error evaluando alertas: {e}\")\n",
    "        return ['‚ö†Ô∏è Error en evaluaci√≥n de alertas']\n",
    "\n",
    "\n",
    "def mostrar_resumen_sistema():\n",
    "    \"\"\"Muestra resumen completo del sistema de forma segura\"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìã RESUMEN DEL SISTEMA MIP QUILLOTA\")\n",
    "        print(\"=\"*60)\n",
    "        print(\n",
    "            f\"üåç Ubicaci√≥n: {\n",
    "                QUILLOTA_CONFIG['ubicacion']['nombre']}, {\n",
    "                QUILLOTA_CONFIG['ubicacion']['region']}\")\n",
    "        print(\n",
    "            f\"üìç Coordenadas: {\n",
    "                QUILLOTA_CONFIG['ubicacion']['latitud']}, {\n",
    "                QUILLOTA_CONFIG['ubicacion']['longitud']}\")\n",
    "        print(f\"üå°Ô∏è Clima: {QUILLOTA_CONFIG['clima']['tipo']}\")\n",
    "        print(\n",
    "            f\"üå± Cultivos: {\n",
    "                ', '.join(\n",
    "                    QUILLOTA_CONFIG['agricultura']['cultivos_principales'])}\")\n",
    "        print(\n",
    "            f\"üíß Riego: {\n",
    "                QUILLOTA_CONFIG['agricultura']['riego']['sistema_principal']}\")\n",
    "        print(f\"üñ•Ô∏è  Contexto: {EXECUTION_CONTEXT}\")\n",
    "        print(\n",
    "            f\"üìä Streamlit: {\n",
    "                'Disponible' if streamlit_manager.available else 'No disponible'}\")\n",
    "        print(\n",
    "            f\"üìà Plotly: {\n",
    "                'Disponible' if PLOTLY_AVAILABLE else 'No disponible'}\")\n",
    "        print(f\"ü§ñ ML: {'Disponible' if ML_AVAILABLE else 'No disponible'}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Generar datos de prueba\n",
    "        datos_prueba = crear_datos_meteorologicos(30)\n",
    "        print(f\"‚úÖ Datos de prueba generados: {len(datos_prueba)} d√≠as\")\n",
    "        print(f\"üìà Temp m√°xima: {datos_prueba['temperatura_max'].max():.1f}¬∞C\")\n",
    "        print(f\"üìâ Temp m√≠nima: {datos_prueba['temperatura_min'].min():.1f}¬∞C\")\n",
    "        print(\n",
    "            f\"üåßÔ∏è Precipitaci√≥n total: {\n",
    "                datos_prueba['precipitacion'].sum():.1f} mm\")\n",
    "\n",
    "        # Evaluar alertas del √∫ltimo d√≠a\n",
    "        ultimo_dia = datos_prueba.iloc[-1]\n",
    "        alertas_hoy = evaluar_alertas(ultimo_dia)\n",
    "        print(f\"\\nüö® ALERTAS DEL D√çA:\")\n",
    "        for alerta in alertas_hoy:\n",
    "            print(f\"   {alerta}\")\n",
    "\n",
    "        return datos_prueba\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en resumen del sistema: {e}\")\n",
    "        return crear_datos_meteorologicos(7)  # Datos m√≠nimos\n",
    "\n",
    "# ===============================================================================\n",
    "# FUNCIONES ADICIONALES DE UTILIDAD\n",
    "# ===============================================================================\n",
    "\n",
    "\n",
    "def verificar_dependencias():\n",
    "    \"\"\"Verifica que todas las dependencias est√©n disponibles\"\"\"\n",
    "    dependencias = {\n",
    "        'pandas': 'pd' in globals(),\n",
    "        'numpy': 'np' in globals(),\n",
    "        'matplotlib': 'plt' in globals(),\n",
    "        'plotly': PLOTLY_AVAILABLE,\n",
    "        'streamlit': streamlit_manager.available,\n",
    "        'sklearn': ML_AVAILABLE\n",
    "    }\n",
    "\n",
    "    print(\"\\nüîç VERIFICACI√ìN DE DEPENDENCIAS:\")\n",
    "    for dep, disponible in dependencias.items():\n",
    "        estado = \"‚úÖ\" if disponible else \"‚ùå\"\n",
    "        print(f\"   {estado} {dep}\")\n",
    "\n",
    "    return dependencias\n",
    "\n",
    "\n",
    "def crear_estructura_directorios():\n",
    "    \"\"\"Crea la estructura de directorios del proyecto si no existe\"\"\"\n",
    "    directorios = {\n",
    "        'notebooks': NOTEBOOKS_DIR if 'NOTEBOOKS_DIR' in globals() else Path('notebooks'),\n",
    "        'src': SRC_DIR if 'SRC_DIR' in globals() else Path('src'),\n",
    "        'data': DATA_DIR if 'DATA_DIR' in globals() else Path('data'),\n",
    "        'docs': DOCS_DIR if 'DOCS_DIR' in globals() else Path('docs'),\n",
    "        'tests': TESTS_DIR if 'TESTS_DIR' in globals() else Path('tests')\n",
    "    }\n",
    "\n",
    "    print(\"\\nüìÅ CREANDO ESTRUCTURA DE DIRECTORIOS:\")\n",
    "    for nombre, directorio in directorios.items():\n",
    "        try:\n",
    "            directorio.mkdir(exist_ok=True)\n",
    "            print(f\"   ‚úÖ {nombre}: {directorio}\")\n",
    "\n",
    "            # Crear subdirectorios espec√≠ficos\n",
    "            if nombre == 'data':\n",
    "                for subdir in ['raw', 'processed', 'external']:\n",
    "                    (directorio / subdir).mkdir(exist_ok=True)\n",
    "            elif nombre == 'src':\n",
    "                for subdir in ['data_processing',\n",
    "                               'models', 'visualization', 'utils']:\n",
    "                    (directorio / subdir).mkdir(exist_ok=True)\n",
    "                    # Crear __init__.py\n",
    "                    (directorio / subdir / '__init__.py').touch()\n",
    "            elif nombre == 'tests':\n",
    "                for subdir in ['unit', 'integration']:\n",
    "                    (directorio / subdir).mkdir(exist_ok=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {nombre}: Error - {e}\")\n",
    "\n",
    "# ===============================================================================\n",
    "# VERIFICACI√ìN FINAL Y MENSAJE DE √âXITO\n",
    "# ===============================================================================\n",
    "\n",
    "\n",
    "print(\"\\nüéâ ¬°Sistema MIP Quillota configurado exitosamente!\")\n",
    "print(\"üîß Configuraci√≥n reparada y optimizada\")\n",
    "print(\"üìö Todos los imports manejados de forma segura\")\n",
    "print(\"‚öôÔ∏è Funciones utilitarias disponibles\")\n",
    "\n",
    "# Verificar dependencias autom√°ticamente\n",
    "deps_disponibles = verificar_dependencias()\n",
    "\n",
    "# Mostrar resumen autom√°ticamente\n",
    "datos_sistema = mostrar_resumen_sistema()\n",
    "\n",
    "# Crear estructura de directorios si es necesario\n",
    "try:\n",
    "    crear_estructura_directorios()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è No se pudo crear estructura completa: {e}\")\n",
    "\n",
    "print(\"\\nüöÄ Configuraci√≥n completa - Sistema listo para usar\")\n",
    "print(\"üìñ Este archivo puede ser importado por otros notebooks\")\n",
    "print(\"üîó Use %run para ejecutar desde otros notebooks\")\n",
    "\n",
    "# Variables globales disponibles para otros notebooks\n",
    "__all__ = [\n",
    "    'QUILLOTA_CONFIG',\n",
    "    'UMBRALES_CRITICOS',\n",
    "    'st',\n",
    "    'streamlit_manager',\n",
    "    'crear_datos_meteorologicos',\n",
    "    'evaluar_alertas',\n",
    "    'mostrar_resumen_sistema',\n",
    "    'EXECUTION_CONTEXT',\n",
    "    'PLOTLY_AVAILABLE',\n",
    "    'ML_AVAILABLE'\n",
    "]\n",
    "\n",
    "print(f\"\\nüìã Variables disponibles: {len(__all__)} elementos exportados\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
