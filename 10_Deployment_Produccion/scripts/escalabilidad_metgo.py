#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üöÄ ESCALABILIDAD METGO 3D
Sistema Meteorol√≥gico Agr√≠cola Quillota - Escalabilidad y Distribuci√≥n
"""

import os
import sys
import time
import json
import asyncio
import threading
import multiprocessing
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging
import sqlite3
import numpy as np
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import queue
import psutil
import requests
from dataclasses import dataclass
import yaml
# import redis
# import pika
# from flask import Flask, request, jsonify
# import uvicorn
# from fastapi import FastAPI, BackgroundTasks
# import docker
# import kubernetes
# import consul
# import etcd3

# Configuraci√≥n
warnings.filterwarnings('ignore')

@dataclass
class NodoServicio:
    """Nodo de servicio en el cluster"""
    id: str
    nombre: str
    tipo: str
    host: str
    puerto: int
    estado: str
    carga: float
    recursos: Dict[str, Any]
    metadata: Dict[str, Any] = None

@dataclass
class ClusterConfig:
    """Configuraci√≥n del cluster"""
    nombre: str
    nodos: List[NodoServicio]
    balanceador: str
    discovery: str
    configuracion: Dict[str, Any]
    metadata: Dict[str, Any] = None

class EscalabilidadMETGO:
    """Sistema de escalabilidad para METGO 3D"""
    
    def __init__(self):
        self.configuracion = {
            'directorio_datos': 'data/escalabilidad',
            'directorio_logs': 'logs/escalabilidad',
            'directorio_config': 'config/escalabilidad',
            'version': '2.0',
            'timestamp': datetime.now().isoformat()
        }
        
        # Crear directorios
        self._crear_directorios()
        
        # Configurar logging
        self._configurar_logging()
        
        # Configuraci√≥n de escalabilidad
        self.configuracion_escalabilidad = {
            'habilitar_auto_scaling': True,
            'habilitar_load_balancing': True,
            'habilitar_service_discovery': True,
            'habilitar_health_checks': True,
            'habilitar_metrics_collection': True,
            'habilitar_distributed_caching': True,
            'habilitar_message_queue': True,
            'habilitar_container_orchestration': True
        }
        
        # Cluster de servicios
        self.cluster_servicios = []
        self.balanceador = None
        self.service_discovery = None
        
        # M√©tricas de escalabilidad
        self.metricas_escalabilidad = []
        
        # Base de datos
        self._inicializar_base_datos()
        
        # Configurar servicios
        self._configurar_servicios()
    
    def _crear_directorios(self):
        """Crear directorios necesarios"""
        try:
            for directorio in self.configuracion.values():
                if isinstance(directorio, str) and '/' in directorio:
                    Path(directorio).mkdir(parents=True, exist_ok=True)
        except Exception as e:
            print(f"Error creando directorios: {e}")
    
    def _configurar_logging(self):
        """Configurar sistema de logging"""
        try:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.FileHandler(f"{self.configuracion['directorio_logs']}/escalabilidad.log"),
                    logging.StreamHandler()
                ]
            )
            self.logger = logging.getLogger('METGO_ESCALABILIDAD')
            self.logger.info("Sistema de logging configurado")
        except Exception as e:
            print(f"Error configurando logging: {e}")
    
    def _inicializar_base_datos(self):
        """Inicializar base de datos SQLite"""
        try:
            archivo_bd = f"{self.configuracion['directorio_datos']}/escalabilidad.db"
            
            self.conexion_bd = sqlite3.connect(archivo_bd, check_same_thread=False)
            self.cursor_bd = self.conexion_bd.cursor()
            
            # Crear tablas
            self._crear_tablas_bd()
            
            self.logger.info(f"Base de datos inicializada: {archivo_bd}")
            
        except Exception as e:
            self.logger.error(f"Error inicializando base de datos: {e}")
    
    def _crear_tablas_bd(self):
        """Crear tablas en la base de datos"""
        try:
            # Tabla de nodos
            self.cursor_bd.execute('''
                CREATE TABLE IF NOT EXISTS nodos (
                    id TEXT PRIMARY KEY,
                    nombre TEXT NOT NULL,
                    tipo TEXT NOT NULL,
                    host TEXT NOT NULL,
                    puerto INTEGER NOT NULL,
                    estado TEXT NOT NULL,
                    carga REAL NOT NULL,
                    recursos TEXT NOT NULL,
                    metadata TEXT,
                    fecha_creacion DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de m√©tricas de escalabilidad
            self.cursor_bd.execute('''
                CREATE TABLE IF NOT EXISTS metricas_escalabilidad (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME NOT NULL,
                    nodo_id TEXT NOT NULL,
                    cpu_uso REAL NOT NULL,
                    memoria_uso REAL NOT NULL,
                    requests_por_segundo REAL NOT NULL,
                    latencia_promedio REAL NOT NULL,
                    errores_por_segundo REAL NOT NULL,
                    metadata TEXT,
                    fecha_creacion DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de eventos de escalabilidad
            self.cursor_bd.execute('''
                CREATE TABLE IF NOT EXISTS eventos_escalabilidad (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME NOT NULL,
                    tipo TEXT NOT NULL,
                    nodo_id TEXT,
                    accion TEXT NOT NULL,
                    motivo TEXT,
                    metadata TEXT,
                    fecha_creacion DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Crear √≠ndices
            self.cursor_bd.execute('CREATE INDEX IF NOT EXISTS idx_nodos_estado ON nodos(estado)')
            self.cursor_bd.execute('CREATE INDEX IF NOT EXISTS idx_metricas_timestamp ON metricas_escalabilidad(timestamp)')
            self.cursor_bd.execute('CREATE INDEX IF NOT EXISTS idx_metricas_nodo ON metricas_escalabilidad(nodo_id)')
            self.cursor_bd.execute('CREATE INDEX IF NOT EXISTS idx_eventos_timestamp ON eventos_escalabilidad(timestamp)')
            self.cursor_bd.execute('CREATE INDEX IF NOT EXISTS idx_eventos_tipo ON eventos_escalabilidad(tipo)')
            
            self.conexion_bd.commit()
            self.logger.info("Tablas de base de datos creadas")
            
        except Exception as e:
            self.logger.error(f"Error creando tablas: {e}")
    
    def _configurar_servicios(self):
        """Configurar servicios del cluster"""
        try:
            # Configurar nodos de servicios
            self._configurar_nodos_servicios()
            
            # Configurar balanceador de carga
            if self.configuracion_escalabilidad['habilitar_load_balancing']:
                self._configurar_balanceador()
            
            # Configurar service discovery
            if self.configuracion_escalabilidad['habilitar_service_discovery']:
                self._configurar_service_discovery()
            
            # Configurar distributed caching
            if self.configuracion_escalabilidad['habilitar_distributed_caching']:
                self._configurar_distributed_caching()
            
            # Configurar message queue
            if self.configuracion_escalabilidad['habilitar_message_queue']:
                self._configurar_message_queue()
            
            self.logger.info("Servicios del cluster configurados")
            
        except Exception as e:
            self.logger.error(f"Error configurando servicios: {e}")
    
    def _configurar_nodos_servicios(self):
        """Configurar nodos de servicios"""
        try:
            # Nodos de API
            nodos_api = [
                NodoServicio(
                    id="api_001",
                    nombre="API Principal 1",
                    tipo="api",
                    host="localhost",
                    puerto=5000,
                    estado="activo",
                    carga=0.0,
                    recursos={"cpu": 2, "memoria": 4, "disco": 20}
                ),
                NodoServicio(
                    id="api_002",
                    nombre="API Principal 2",
                    tipo="api",
                    host="localhost",
                    puerto=5001,
                    estado="activo",
                    carga=0.0,
                    recursos={"cpu": 2, "memoria": 4, "disco": 20}
                )
            ]
            
            # Nodos de base de datos
            nodos_db = [
                NodoServicio(
                    id="db_001",
                    nombre="Base de Datos Principal",
                    tipo="database",
                    host="localhost",
                    puerto=5432,
                    estado="activo",
                    carga=0.0,
                    recursos={"cpu": 4, "memoria": 8, "disco": 100}
                )
            ]
            
            # Nodos de cache
            nodos_cache = [
                NodoServicio(
                    id="cache_001",
                    nombre="Redis Cache 1",
                    tipo="cache",
                    host="localhost",
                    puerto=6379,
                    estado="activo",
                    carga=0.0,
                    recursos={"cpu": 1, "memoria": 2, "disco": 10}
                )
            ]
            
            # Nodos de monitoreo
            nodos_monitoreo = [
                NodoServicio(
                    id="monitor_001",
                    nombre="Monitoreo Principal",
                    tipo="monitoring",
                    host="localhost",
                    puerto=8051,
                    estado="activo",
                    carga=0.0,
                    recursos={"cpu": 1, "memoria": 2, "disco": 10}
                )
            ]
            
            # Agregar todos los nodos
            self.cluster_servicios.extend(nodos_api)
            self.cluster_servicios.extend(nodos_db)
            self.cluster_servicios.extend(nodos_cache)
            self.cluster_servicios.extend(nodos_monitoreo)
            
            # Guardar nodos en base de datos
            for nodo in self.cluster_servicios:
                self._guardar_nodo(nodo)
            
            self.logger.info(f"Configurados {len(self.cluster_servicios)} nodos de servicios")
            
        except Exception as e:
            self.logger.error(f"Error configurando nodos de servicios: {e}")
    
    def _configurar_balanceador(self):
        """Configurar balanceador de carga"""
        try:
            # Configuraci√≥n del balanceador
            self.balanceador = {
                'tipo': 'nginx',
                'algoritmo': 'round_robin',
                'health_check': True,
                'sticky_sessions': False,
                'configuracion': {
                    'upstream_servers': [
                        {'host': 'localhost', 'port': 5000, 'weight': 1},
                        {'host': 'localhost', 'port': 5001, 'weight': 1}
                    ],
                    'health_check_interval': 30,
                    'health_check_timeout': 5,
                    'max_fails': 3
                }
            }
            
            self.logger.info("Balanceador de carga configurado")
            
        except Exception as e:
            self.logger.error(f"Error configurando balanceador: {e}")
    
    def _configurar_service_discovery(self):
        """Configurar service discovery"""
        try:
            # Configuraci√≥n de service discovery
            self.service_discovery = {
                'tipo': 'consul',
                'host': 'localhost',
                'puerto': 8500,
                'configuracion': {
                    'datacenter': 'metgo3d',
                    'encrypt': False,
                    'acl': False,
                    'services': [
                        {
                            'name': 'metgo3d-api',
                            'port': 5000,
                            'health_check': '/health',
                            'tags': ['api', 'meteorologia']
                        }
                    ]
                }
            }
            
            self.logger.info("Service discovery configurado")
            
        except Exception as e:
            self.logger.error(f"Error configurando service discovery: {e}")
    
    def _configurar_distributed_caching(self):
        """Configurar distributed caching"""
        try:
            # Configuraci√≥n de Redis
            self.redis_config = {
                'host': 'localhost',
                'puerto': 6379,
                'db': 0,
                'password': None,
                'timeout': 5,
                'max_connections': 10,
                'configuracion': {
                    'maxmemory': '256mb',
                    'maxmemory_policy': 'allkeys-lru',
                    'save': '900 1 300 10 60 10000'
                }
            }
            
            self.logger.info("Distributed caching configurado")
            
        except Exception as e:
            self.logger.error(f"Error configurando distributed caching: {e}")
    
    def _configurar_message_queue(self):
        """Configurar message queue"""
        try:
            # Configuraci√≥n de RabbitMQ
            self.rabbitmq_config = {
                'host': 'localhost',
                'puerto': 5672,
                'usuario': 'metgo3d',
                'password': 'metgo3d_2024_secure',
                'vhost': '/',
                'configuracion': {
                    'exchanges': [
                        {
                            'name': 'metgo3d.exchange',
                            'type': 'topic',
                            'durable': True
                        }
                    ],
                    'queues': [
                        {
                            'name': 'metgo3d.alerts',
                            'durable': True,
                            'auto_delete': False
                        },
                        {
                            'name': 'metgo3d.metrics',
                            'durable': True,
                            'auto_delete': False
                        }
                    ]
                }
            }
            
            self.logger.info("Message queue configurado")
            
        except Exception as e:
            self.logger.error(f"Error configurando message queue: {e}")
    
    def _guardar_nodo(self, nodo: NodoServicio):
        """Guardar nodo en la base de datos"""
        try:
            self.cursor_bd.execute('''
                INSERT OR REPLACE INTO nodos 
                (id, nombre, tipo, host, puerto, estado, carga, recursos, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                nodo.id,
                nodo.nombre,
                nodo.tipo,
                nodo.host,
                nodo.puerto,
                nodo.estado,
                nodo.carga,
                json.dumps(nodo.recursos),
                json.dumps(nodo.metadata) if nodo.metadata else None
            ))
            
            self.conexion_bd.commit()
            
        except Exception as e:
            self.logger.error(f"Error guardando nodo: {e}")
    
    def monitorear_nodos(self) -> List[Dict[str, Any]]:
        """Monitorear estado de los nodos"""
        try:
            self.logger.info("Monitoreando nodos del cluster...")
            
            metricas_nodos = []
            
            for nodo in self.cluster_servicios:
                try:
                    # Obtener m√©tricas del nodo
                    metricas = self._obtener_metricas_nodo(nodo)
                    
                    # Actualizar estado del nodo
                    self._actualizar_estado_nodo(nodo, metricas)
                    
                    # Guardar m√©tricas
                    self._guardar_metricas_escalabilidad(nodo.id, metricas)
                    
                    metricas_nodos.append({
                        'nodo_id': nodo.id,
                        'nombre': nodo.nombre,
                        'tipo': nodo.tipo,
                        'estado': nodo.estado,
                        'carga': nodo.carga,
                        'metricas': metricas
                    })
                    
                except Exception as e:
                    self.logger.error(f"Error monitoreando nodo {nodo.id}: {e}")
                    # Marcar nodo como inactivo
                    nodo.estado = 'inactivo'
                    self._guardar_nodo(nodo)
            
            self.logger.info(f"Monitoreo completado para {len(metricas_nodos)} nodos")
            return metricas_nodos
            
        except Exception as e:
            self.logger.error(f"Error monitoreando nodos: {e}")
            return []
    
    def _obtener_metricas_nodo(self, nodo: NodoServicio) -> Dict[str, Any]:
        """Obtener m√©tricas de un nodo"""
        try:
            # M√©tricas del sistema
            cpu_uso = psutil.cpu_percent(interval=1)
            memoria = psutil.virtual_memory()
            memoria_uso = memoria.percent
            
            # M√©tricas de red
            red = psutil.net_io_counters()
            requests_por_segundo = (red.packets_sent + red.packets_recv) / 60  # Aproximaci√≥n
            
            # Latencia simulada
            latencia_promedio = 0.05  # 50ms
            
            # Errores simulados
            errores_por_segundo = 0.1  # 0.1 errores por segundo
            
            return {
                'cpu_uso': cpu_uso,
                'memoria_uso': memoria_uso,
                'requests_por_segundo': requests_por_segundo,
                'latencia_promedio': latencia_promedio,
                'errores_por_segundo': errores_por_segundo,
                'timestamp': datetime.now()
            }
            
        except Exception as e:
            self.logger.error(f"Error obteniendo m√©tricas del nodo {nodo.id}: {e}")
            return {}
    
    def _actualizar_estado_nodo(self, nodo: NodoServicio, metricas: Dict[str, Any]):
        """Actualizar estado de un nodo basado en m√©tricas"""
        try:
            # Calcular carga del nodo
            carga = (metricas.get('cpu_uso', 0) + metricas.get('memoria_uso', 0)) / 2
            nodo.carga = carga
            
            # Determinar estado del nodo
            if carga > 90:
                nodo.estado = 'sobrecargado'
            elif carga > 70:
                nodo.estado = 'alto'
            elif carga > 30:
                nodo.estado = 'normal'
            else:
                nodo.estado = 'bajo'
            
            # Actualizar en base de datos
            self._guardar_nodo(nodo)
            
        except Exception as e:
            self.logger.error(f"Error actualizando estado del nodo {nodo.id}: {e}")
    
    def _guardar_metricas_escalabilidad(self, nodo_id: str, metricas: Dict[str, Any]):
        """Guardar m√©tricas de escalabilidad"""
        try:
            self.cursor_bd.execute('''
                INSERT INTO metricas_escalabilidad 
                (timestamp, nodo_id, cpu_uso, memoria_uso, requests_por_segundo, latencia_promedio, errores_por_segundo, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                metricas.get('timestamp', datetime.now()),
                nodo_id,
                metricas.get('cpu_uso', 0),
                metricas.get('memoria_uso', 0),
                metricas.get('requests_por_segundo', 0),
                metricas.get('latencia_promedio', 0),
                metricas.get('errores_por_segundo', 0),
                json.dumps(metricas)
            ))
            
            self.conexion_bd.commit()
            
        except Exception as e:
            self.logger.error(f"Error guardando m√©tricas de escalabilidad: {e}")
    
    def evaluar_escalabilidad(self) -> Dict[str, Any]:
        """Evaluar necesidad de escalabilidad"""
        try:
            self.logger.info("Evaluando escalabilidad...")
            
            # Obtener m√©tricas de todos los nodos
            metricas_nodos = self.monitorear_nodos()
            
            # Analizar carga del cluster
            carga_total = sum(nodo['metricas'].get('cpu_uso', 0) for nodo in metricas_nodos)
            carga_promedio = carga_total / len(metricas_nodos) if metricas_nodos else 0
            
            # Contar nodos por estado
            nodos_sobrecargados = sum(1 for nodo in metricas_nodos if nodo['estado'] == 'sobrecargado')
            nodos_altos = sum(1 for nodo in metricas_nodos if nodo['estado'] == 'alto')
            nodos_normales = sum(1 for nodo in metricas_nodos if nodo['estado'] == 'normal')
            nodos_bajos = sum(1 for nodo in metricas_nodos if nodo['estado'] == 'bajo')
            
            # Determinar acciones de escalabilidad
            acciones = []
            
            if nodos_sobrecargados > 0:
                acciones.append({
                    'tipo': 'escalar_horizontal',
                    'prioridad': 'alta',
                    'descripcion': f'{nodos_sobrecargados} nodos sobrecargados',
                    'accion': 'Agregar nuevos nodos'
                })
            
            if carga_promedio > 80:
                acciones.append({
                    'tipo': 'escalar_vertical',
                    'prioridad': 'media',
                    'descripcion': f'Carga promedio alta: {carga_promedio:.1f}%',
                    'accion': 'Aumentar recursos de nodos existentes'
                })
            
            if nodos_bajos > len(metricas_nodos) * 0.5:
                acciones.append({
                    'tipo': 'escalar_hacia_abajo',
                    'prioridad': 'baja',
                    'descripcion': f'{nodos_bajos} nodos con carga baja',
                    'accion': 'Reducir n√∫mero de nodos'
                })
            
            evaluacion = {
                'timestamp': datetime.now(),
                'carga_promedio': carga_promedio,
                'nodos_totales': len(metricas_nodos),
                'nodos_sobrecargados': nodos_sobrecargados,
                'nodos_altos': nodos_altos,
                'nodos_normales': nodos_normales,
                'nodos_bajos': nodos_bajos,
                'acciones': acciones,
                'recomendacion': self._generar_recomendacion_escalabilidad(acciones)
            }
            
            self.logger.info(f"Evaluaci√≥n de escalabilidad completada: {len(acciones)} acciones recomendadas")
            return evaluacion
            
        except Exception as e:
            self.logger.error(f"Error evaluando escalabilidad: {e}")
            return {}
    
    def _generar_recomendacion_escalabilidad(self, acciones: List[Dict[str, Any]]) -> str:
        """Generar recomendaci√≥n de escalabilidad"""
        try:
            if not acciones:
                return "El cluster est√° funcionando normalmente, no se requieren acciones de escalabilidad."
            
            # Priorizar acciones
            acciones_altas = [a for a in acciones if a['prioridad'] == 'alta']
            acciones_medias = [a for a in acciones if a['prioridad'] == 'media']
            acciones_bajas = [a for a in acciones if a['prioridad'] == 'baja']
            
            recomendacion = "Recomendaciones de escalabilidad:\n"
            
            if acciones_altas:
                recomendacion += "URGENTE:\n"
                for accion in acciones_altas:
                    recomendacion += f"- {accion['descripcion']}: {accion['accion']}\n"
            
            if acciones_medias:
                recomendacion += "MEDIO PLAZO:\n"
                for accion in acciones_medias:
                    recomendacion += f"- {accion['descripcion']}: {accion['accion']}\n"
            
            if acciones_bajas:
                recomendacion += "LARGO PLAZO:\n"
                for accion in acciones_bajas:
                    recomendacion += f"- {accion['descripcion']}: {accion['accion']}\n"
            
            return recomendacion
            
        except Exception as e:
            self.logger.error(f"Error generando recomendaci√≥n: {e}")
            return "Error generando recomendaci√≥n de escalabilidad."
    
    def ejecutar_escalabilidad_completa(self) -> Dict[str, Any]:
        """Ejecutar an√°lisis completo de escalabilidad"""
        try:
            self.logger.info("Iniciando an√°lisis completo de escalabilidad...")
            
            inicio = time.time()
            resultados = {}
            
            # Monitorear nodos
            metricas_nodos = self.monitorear_nodos()
            resultados['metricas_nodos'] = metricas_nodos
            
            # Evaluar escalabilidad
            evaluacion = self.evaluar_escalabilidad()
            resultados['evaluacion'] = evaluacion
            
            # Generar estad√≠sticas del cluster
            estadisticas = self._generar_estadisticas_cluster()
            resultados['estadisticas'] = estadisticas
            
            # Generar recomendaciones
            recomendaciones = self._generar_recomendaciones()
            resultados['recomendaciones'] = recomendaciones
            
            duracion = time.time() - inicio
            resultados['duracion'] = duracion
            resultados['exitoso'] = True
            
            self.logger.info(f"An√°lisis de escalabilidad completado en {duracion:.2f} segundos")
            return resultados
            
        except Exception as e:
            self.logger.error(f"Error ejecutando escalabilidad completa: {e}")
            return {'exitoso': False, 'error': str(e)}
    
    def _generar_estadisticas_cluster(self) -> Dict[str, Any]:
        """Generar estad√≠sticas del cluster"""
        try:
            # Obtener m√©tricas recientes
            self.cursor_bd.execute('''
                SELECT * FROM metricas_escalabilidad 
                WHERE timestamp > datetime('now', '-1 hour')
                ORDER BY timestamp DESC
            ''')
            metricas_recientes = self.cursor_bd.fetchall()
            
            if not metricas_recientes:
                return {}
            
            # Calcular estad√≠sticas
            cpu_promedio = sum(m[2] for m in metricas_recientes) / len(metricas_recientes)
            memoria_promedio = sum(m[3] for m in metricas_recientes) / len(metricas_recientes)
            requests_promedio = sum(m[4] for m in metricas_recientes) / len(metricas_recientes)
            latencia_promedio = sum(m[5] for m in metricas_recientes) / len(metricas_recientes)
            errores_promedio = sum(m[6] for m in metricas_recientes) / len(metricas_recientes)
            
            return {
                'periodo': '1 hora',
                'total_metricas': len(metricas_recientes),
                'cpu_promedio': cpu_promedio,
                'memoria_promedio': memoria_promedio,
                'requests_promedio': requests_promedio,
                'latencia_promedio': latencia_promedio,
                'errores_promedio': errores_promedio,
                'nodos_activos': len(self.cluster_servicios),
                'timestamp': datetime.now()
            }
            
        except Exception as e:
            self.logger.error(f"Error generando estad√≠sticas del cluster: {e}")
            return {}
    
    def _generar_recomendaciones(self) -> List[Dict[str, Any]]:
        """Generar recomendaciones de escalabilidad"""
        try:
            recomendaciones = []
            
            # Recomendaci√≥n de monitoreo
            recomendaciones.append({
                'tipo': 'monitoreo',
                'prioridad': 'alta',
                'titulo': 'Monitoreo Continuo',
                'descripcion': 'Implementar monitoreo continuo de m√©tricas de escalabilidad',
                'accion': 'Configurar alertas autom√°ticas para umbrales de carga'
            })
            
            # Recomendaci√≥n de auto-scaling
            recomendaciones.append({
                'tipo': 'auto_scaling',
                'prioridad': 'media',
                'titulo': 'Auto-scaling Horizontal',
                'descripcion': 'Implementar auto-scaling horizontal basado en m√©tricas',
                'accion': 'Configurar pol√≠ticas de auto-scaling en Kubernetes'
            })
            
            # Recomendaci√≥n de balanceador
            recomendaciones.append({
                'tipo': 'load_balancing',
                'prioridad': 'media',
                'titulo': 'Balanceador de Carga',
                'descripcion': 'Optimizar configuraci√≥n del balanceador de carga',
                'accion': 'Implementar algoritmos de balanceo m√°s sofisticados'
            })
            
            # Recomendaci√≥n de cache
            recomendaciones.append({
                'tipo': 'caching',
                'prioridad': 'baja',
                'titulo': 'Distributed Caching',
                'descripcion': 'Implementar distributed caching para mejorar rendimiento',
                'accion': 'Configurar Redis cluster para cache distribuido'
            })
            
            return recomendaciones
            
        except Exception as e:
            self.logger.error(f"Error generando recomendaciones: {e}")
            return []
    
    def generar_reporte_escalabilidad(self) -> str:
        """Generar reporte de escalabilidad"""
        try:
            self.logger.info("Generando reporte de escalabilidad...")
            
            # Ejecutar an√°lisis completo
            resultados = self.ejecutar_escalabilidad_completa()
            
            reporte = {
                'timestamp': datetime.now().isoformat(),
                'sistema': 'METGO 3D - Escalabilidad',
                'version': self.configuracion['version'],
                'configuracion': self.configuracion_escalabilidad,
                'resultados': resultados,
                'cluster': {
                    'nodos_totales': len(self.cluster_servicios),
                    'tipos_nodos': list(set(nodo.tipo for nodo in self.cluster_servicios)),
                    'balanceador': self.balanceador,
                    'service_discovery': self.service_discovery
                },
                'recomendaciones': [
                    "Implementar monitoreo continuo de m√©tricas",
                    "Configurar auto-scaling horizontal",
                    "Optimizar balanceador de carga",
                    "Implementar distributed caching",
                    "Configurar service discovery",
                    "Implementar health checks",
                    "Configurar message queue",
                    "Considerar container orchestration"
                ]
            }
            
            # Guardar reporte
            reportes_dir = Path("reportes")
            reportes_dir.mkdir(exist_ok=True)
            
            reporte_file = reportes_dir / f"escalabilidad_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(reporte_file, 'w', encoding='utf-8') as f:
                json.dump(reporte, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"Reporte de escalabilidad generado: {reporte_file}")
            return str(reporte_file)
            
        except Exception as e:
            self.logger.error(f"Error generando reporte: {e}")
            return ""

def main():
    """Funci√≥n principal de escalabilidad"""
    print("üöÄ ESCALABILIDAD METGO 3D")
    print("Sistema Meteorol√≥gico Agr√≠cola Quillota - Escalabilidad y Distribuci√≥n")
    print("=" * 80)
    
    try:
        # Crear sistema de escalabilidad
        escalabilidad = EscalabilidadMETGO()
        
        # Ejecutar an√°lisis completo
        print(f"\nüöÄ Ejecutando an√°lisis de escalabilidad...")
        resultados = escalabilidad.ejecutar_escalabilidad_completa()
        
        if resultados.get('exitoso'):
            print(f"‚úÖ An√°lisis de escalabilidad completado exitosamente")
            print(f"‚è±Ô∏è Duraci√≥n: {resultados.get('duracion', 0):.2f} segundos")
            
            # Mostrar m√©tricas de nodos
            metricas_nodos = resultados.get('metricas_nodos', [])
            print(f"\nüìä Nodos monitoreados: {len(metricas_nodos)}")
            for nodo in metricas_nodos:
                print(f"   - {nodo['nombre']}: {nodo['estado']} (carga: {nodo['carga']:.1f}%)")
            
            # Mostrar evaluaci√≥n
            evaluacion = resultados.get('evaluacion', {})
            if evaluacion:
                print(f"\nüìà Evaluaci√≥n de escalabilidad:")
                print(f"   Carga promedio: {evaluacion.get('carga_promedio', 0):.1f}%")
                print(f"   Nodos sobrecargados: {evaluacion.get('nodos_sobrecargados', 0)}")
                print(f"   Acciones recomendadas: {len(evaluacion.get('acciones', []))}")
                
                # Mostrar acciones
                acciones = evaluacion.get('acciones', [])
                if acciones:
                    print(f"\nüîß Acciones recomendadas:")
                    for accion in acciones:
                        print(f"   - {accion['prioridad'].upper()}: {accion['descripcion']}")
            
            # Mostrar estad√≠sticas
            estadisticas = resultados.get('estadisticas', {})
            if estadisticas:
                print(f"\nüìä Estad√≠sticas del cluster:")
                print(f"   CPU promedio: {estadisticas.get('cpu_promedio', 0):.1f}%")
                print(f"   Memoria promedio: {estadisticas.get('memoria_promedio', 0):.1f}%")
                print(f"   Requests promedio: {estadisticas.get('requests_promedio', 0):.1f}/s")
                print(f"   Latencia promedio: {estadisticas.get('latencia_promedio', 0):.3f}s")
        else:
            print(f"‚ùå Error en an√°lisis de escalabilidad: {resultados.get('error', 'Error desconocido')}")
        
        # Generar reporte
        print(f"\nüìã Generando reporte...")
        reporte = escalabilidad.generar_reporte_escalabilidad()
        
        if reporte:
            print(f"‚úÖ Reporte generado: {reporte}")
        else:
            print(f"‚ö†Ô∏è Error generando reporte")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Error en escalabilidad: {e}")
        return False

if __name__ == "__main__":
    try:
        exito = main()
        sys.exit(0 if exito else 1)
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        sys.exit(1)
